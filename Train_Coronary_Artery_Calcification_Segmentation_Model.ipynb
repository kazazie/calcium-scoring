{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Train Coronary Artery Calcification Segmentation Model",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XGsdia1tv514"
      },
      "source": [
        "This colab processes the COCA dataset and trains models using the Keras framework with a number of different architectures, losses, etc"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s251abv_1V28"
      },
      "source": [
        "# Initialize"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UVuYo1Ykn7Ia"
      },
      "source": [
        "!pip install pydicom\n",
        "!pip install tensorflow_addons\n",
        "\n",
        "import ast\n",
        "import collections\n",
        "import dataclasses\n",
        "import datetime\n",
        "import logging\n",
        "import math\n",
        "import matplotlib.patches as patches\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import plistlib\n",
        "import pydicom\n",
        "import pytz\n",
        "import sys\n",
        "import tensorflow as tf\n",
        "from matplotlib.path import Path\n",
        "from tensorflow import keras\n",
        "from typing import Dict, List, Optional, Text, Tuple\n",
        "from tensorflow.python.client import device_lib\n",
        "from tensorflow.keras import backend as K\n",
        "import tensorflow_addons as tfa\n",
        "\n",
        "assert len(tf.config.experimental.list_physical_devices('GPU')) > 0\n",
        "\n",
        "logger = logging.getLogger()\n",
        "logger.setLevel(logging.DEBUG)\n",
        "\n",
        "device_lib.list_local_devices()\n",
        "\n",
        "project_base_dir = ''\n",
        "parsed_lesions_path = ''\n",
        "gated_dir = ''\n",
        "\n",
        "np.random.seed(1216)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mrKBAV9v-bPc"
      },
      "source": [
        "# Constants and Classes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gSUEyRPn-aik"
      },
      "source": [
        "@dataclasses.dataclass\n",
        "class Artery:\n",
        "  name: Text\n",
        "  class_index: int\n",
        "  color: Text\n",
        "\n",
        "@dataclasses.dataclass\n",
        "class Lesion:\n",
        "  points: List[Tuple[float, float]]\n",
        "  artery: Text\n",
        "\n",
        "@dataclasses.dataclass\n",
        "class Slice:\n",
        "  patient_id: Text\n",
        "  image_path: Text \n",
        "  patient_split: Text\n",
        "  has_calcification: bool\n",
        "  lesions: List[Lesion]\n",
        "  image: np.ndarray\n",
        "  ground_truth_mask: np.ndarray\n",
        "\n",
        "ARTERIES = {'Right Coronary Artery': Artery(\n",
        "                name='Right Coronary Artery',\n",
        "                class_index=0,\n",
        "                color='red',),\n",
        "            'Left Anterior Descending Artery': Artery(\n",
        "                name='Left Anterior Descending Artery',\n",
        "                class_index=1,\n",
        "                color='blue',),\n",
        "            'Left Coronary Artery': Artery(\n",
        "                name='Left Coronary Artery',\n",
        "                class_index=2,\n",
        "                color='green',),\n",
        "            'Left Circumflex Artery': Artery(\n",
        "                name='Left Circumflex artery',\n",
        "                class_index=3,\n",
        "                color='yellow',)\n",
        "            }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lTJtfxh6c8_K"
      },
      "source": [
        "# Create CSV (Run Once)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3DxMxjIFnzx-"
      },
      "source": [
        "## Create lesions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "unmTl9jxcl4J"
      },
      "source": [
        "patient_id_to_lesions = get_patient_id_to_lesions(gated_dir) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-btA1qwxaAbt",
        "outputId": "f237dcd1-c4df-4938-8248-dc1c66888f59"
      },
      "source": [
        "def get_lesions(plist: Dict) -> Dict[int, List[Lesion]]:\n",
        "  \"\"\"Get lesion metadata from the parsed XML dict.\n",
        "\n",
        "    Args:\n",
        "      plist: Parsed XML dictionary.\n",
        "    Returns:\n",
        "      Dict[image_index, List[Lesion]]\n",
        "  \"\"\"\n",
        "  def get_point(point):\n",
        "    parsed_point = ast.literal_eval(point)\n",
        "    for point in parsed_point:\n",
        "      assert point > 0 and point <= 512, f'Invalid point {point}'\n",
        "    return parsed_point\n",
        "\n",
        "  image_index_to_lesions = {}\n",
        "  for image in plist['Images']:\n",
        "    image_index = image['ImageIndex']\n",
        "    if image_index in image_index_to_lesions:\n",
        "      raise ValueError(f'For patient {patient_id}, duplicate image index {image_index}')\n",
        "    expected_num_rois = image['NumberOfROIs']\n",
        "    assert (expected_num_rois == len(image['ROIs']),\n",
        "      f'Expected {expected_num_rois} ROIs but found ')\n",
        "    for roi in image['ROIs']:\n",
        "      artery = roi['Name']\n",
        "      if artery not in ARTERIES:\n",
        "        logging.error(f'ROI has unexpected artery {artery}')\n",
        "        continue\n",
        "      if not roi['Point_px']:\n",
        "        continue\n",
        "      points = [get_point(point) for point in roi['Point_px']]\n",
        "      lesion = Lesion(points=points, artery=artery)\n",
        "      # TODO: prettify\n",
        "      if not image_index in image_index_to_lesions:\n",
        "        image_index_to_lesions[image_index] = [lesion]\n",
        "      else:\n",
        "        image_index_to_lesions[image_index].append(lesion)\n",
        "  return image_index_to_lesions\n",
        "\n",
        "def get_patient_id_to_lesions(gated_dir) -> Dict[int, Dict[int, Lesion]]:\n",
        "  \"\"\"Reads all XML data.\n",
        "    Args:\n",
        "      gated_dir: Path to gated directory. All XML files should be unnested in\n",
        "        this folder.\n",
        "    Returns:\n",
        "      Dict[patient_id, Dict[image_index, Lesion]].\n",
        "  \"\"\"\n",
        "  xml_dir = os.path.join(gated_dir, \"calcium_xml\")\n",
        "  patient_id_to_lesions = {}\n",
        "  for _, _, files in os.walk(xml_dir):\n",
        "    for fname in files:\n",
        "      if not fname.endswith('.xml'):\n",
        "        continue\n",
        "      patient_id = int(fname.split('.xml')[0])\n",
        "      if patient_id > 450:\n",
        "        continue\n",
        "      fpath = os.path.join(xml_dir, fname)\n",
        "      with open(fpath, 'rb') as f:\n",
        "        logging.debug(f'Opened {fname}')\n",
        "        plist = plistlib.load(f)\n",
        "        image_index_to_lesions = get_lesions(plist)\n",
        "      patient_id_to_lesions[patient_id] = image_index_to_lesions\n",
        "  return patient_id_to_lesions\n",
        "  \n",
        "  "
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-6-2c4069216ddc>:21: SyntaxWarning: assertion is always true, perhaps remove parentheses?\n",
            "  assert (expected_num_rois == len(image['ROIs']),\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bl-Td0llc4Sp"
      },
      "source": [
        "df_dict = collections.defaultdict(list)\n",
        "\n",
        "images_dir = os.path.join(gated_dir, \"patient\")\n",
        "# images_dir = \"/content/drive/MyDrive/Grad School Dreams/Stanford Grad Certificate/CS230/CS230 Project/Data sample/coca_sample/Gated_release_final/patient\"\n",
        "\n",
        "def add_healthy_image(df_dict, patient_id, relative_image_path, image_index):\n",
        "  df_dict['patient_id'].append(patient_id)\n",
        "  df_dict['image_index'].append(image_index)\n",
        "  df_dict['lesion_points'].append(np.nan)\n",
        "  df_dict['artery'].append(np.nan)\n",
        "  df_dict['artery_class'].append(np.nan)\n",
        "  df_dict['artery_color'].append(np.nan)\n",
        "  df_dict['image_path'].append(relative_image_path)\n",
        "\n",
        "image_count = 0\n",
        "for patient_dir in os.listdir(images_dir):\n",
        "  patient_dir_path = os.path.join(images_dir, patient_dir)\n",
        "  if not os.path.isdir(patient_dir_path):\n",
        "    continue\n",
        "  patient_id = int(patient_dir)\n",
        "  print(f'patient {patient_dir}')\n",
        "  healthy_patient = False\n",
        "  if patient_id > 450:\n",
        "    # Patients 451 and above are known to be healthy patients.\n",
        "    healthy_patient = True\n",
        "  elif patient_id not in patient_id_to_lesions:\n",
        "    logging.error(f'Patient {patient_id} unexpectedly has no metadata. Skipping.')\n",
        "    continue\n",
        "  else:\n",
        "    # Patient has metadata of the form Dict[image_index, List[Lesion]]\n",
        "    image_index_to_lesions = patient_id_to_lesions[patient_id]\n",
        "  for subdir in os.listdir(patient_dir_path):\n",
        "    subdir_path = os.path.join(patient_dir_path, subdir)\n",
        "    if not os.path.isdir(subdir_path):\n",
        "      continue\n",
        "    for image_index, image_name in enumerate(sorted(os.listdir(subdir_path), reverse=True)):\n",
        "      image_count += 1\n",
        "      full_image_path = os.path.join(subdir_path, image_name)\n",
        "      relative_image_path = full_image_path.split('Gated_release_final')[1]\n",
        "      if healthy_patient or image_index not in image_index_to_lesions:\n",
        "        add_healthy_image(df_dict, patient_id, relative_image_path, image_index)\n",
        "      else:\n",
        "        image_lesions = image_index_to_lesions[image_index]\n",
        "        for lesion in image_lesions:\n",
        "          df_dict['patient_id'].append(patient_id)\n",
        "          df_dict['image_index'].append(image_index)\n",
        "          df_dict['lesion_points'].append(lesion.points)\n",
        "          df_dict['artery'].append(lesion.artery)\n",
        "          df_dict['artery_class'].append(ARTERIES[lesion.artery].class_index)\n",
        "          df_dict['artery_color'].append(ARTERIES[lesion.artery].color)\n",
        "          df_dict['image_path'].append(relative_image_path)\n",
        "\n",
        "df = pd.DataFrame(df_dict)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BiAEtiRosAUD"
      },
      "source": [
        "train_dev_fname = '/content/cs230-Coronary-Calcium-Scoring-/dataset/gated_train_dev_pids.dump'\n",
        "test_fname = '/content/cs230-Coronary-Calcium-Scoring-/dataset/gated_test_pids.dump'\n",
        "with open(train_dev_fname, 'rb') as f:\n",
        "  train_patient_ids, dev_patient_ids = pickle.load(f)\n",
        "\n",
        "with open(test_fname, 'rb') as f:\n",
        "  test_patient_ids = pickle.load(f)\n",
        "\n",
        "patient_split_map = {}\n",
        "for pid in train_patient_ids:\n",
        "  patient_split_map[int(pid)] = 'train'\n",
        "for pid in dev_patient_ids:\n",
        "  patient_split_map[int(pid)] = 'tune'\n",
        "for pid in test_patient_ids:\n",
        "  patient_split_map[int(pid)] = 'test'\n",
        "\n",
        "df['patient_split'] = df.patient_id.map(patient_split_map)\n",
        "df['has_calcification'] = df.lesion_points.apply(lambda x: isinstance(x, list))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fU1jNChFsCD2",
        "outputId": "e9ef8359-a015-4d9e-e057-bd9ca5a62033"
      },
      "source": [
        "df.artery.value_counts(normalize=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:numexpr.utils:NumExpr defaulting to 2 threads.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "Left Anterior Descending Artery    0.370996\n",
              "Right Coronary Artery              0.370352\n",
              "Left Circumflex Artery             0.213906\n",
              "Left Coronary Artery               0.044745\n",
              "Name: artery, dtype: float64"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZBCTUEnkr2d_"
      },
      "source": [
        "# Read Parsed Lesions (Run Each Time)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ny3TiBCkr6Dr"
      },
      "source": [
        "def read_parsed_lesions(parsed_lesions_path):\n",
        "  BAD_PATIENT_IDS = set(\n",
        "    [78, 120, 146, 3336, 3309])\n",
        "  def maybe_literal_eval(x):\n",
        "    try:\n",
        "      return ast.literal_eval(x)\n",
        "    except:\n",
        "      return x\n",
        "\n",
        "  with open(parsed_lesions_path, 'r') as f:\n",
        "    df = pd.read_csv(f)\n",
        "  bad_row_indices = df.loc[df.patient_id.isin(BAD_PATIENT_IDS)].index\n",
        "  df = df.drop(index=bad_row_indices)\n",
        "  df['lesion_points'] = df.lesion_points.apply(maybe_literal_eval)\n",
        "  df = df.sample(frac=1, random_state=1216)\n",
        "  return df\n",
        "\n",
        "df = read_parsed_lesions(parsed_lesions_path)\n",
        "train_image_paths = list(df.loc[df.patient_split == 'train'].image_path.unique())\n",
        "tune_image_paths = list(df.loc[df.patient_split == 'tune'].image_path.unique())\n",
        "test_image_paths = list(df.loc[df.patient_split == 'test'].image_path.unique())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aZAsgBEqMD6C"
      },
      "source": [
        "# Visualize lesions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1zzki7LZsT_S"
      },
      "source": [
        "def plot_image_with_overlay(image_slice: Slice, prediction):\n",
        "  image = image_slice.image\n",
        "  ground_truth = image_slice.ground_truth_mask\n",
        "\n",
        "  fig = plt.figure(figsize=(15, 15))\n",
        "  ax = fig.add_subplot(1, 5, 1)\n",
        "  ax.set_title('Original image')\n",
        "  ax.imshow(image, cmap='gray', interpolation=None)\n",
        "  ax = fig.add_subplot(1, 5, 2)\n",
        "  ax.set_title('Ground truth mask')\n",
        "  ax.imshow(ground_truth, cmap='gray', interpolation=None)\n",
        "  ax = fig.add_subplot(1, 5, 3)\n",
        "  ax.set_title('Image with ground truth mask')\n",
        "  ax.imshow(image, cmap='gray', interpolation=None)\n",
        "  ax.imshow(ground_truth, cmap='gray', alpha=0.5, interpolation=None)\n",
        "  # if prediction:\n",
        "  ax = fig.add_subplot(1, 5, 4)\n",
        "  ax.set_title('Predicted mask')\n",
        "  ax.imshow(prediction, cmap='gray', interpolation=None)\n",
        "\n",
        "  ax = fig.add_subplot(1, 5, 5)\n",
        "  ax.set_title('Image with predicted mask')\n",
        "  ax.imshow(image, cmap='gray', interpolation=None)\n",
        "  ax.imshow(prediction, cmap='gray', alpha=0.5, interpolation=None)\n",
        "\n",
        "def plot_image_slice(image_slice: Slice, prediction):\n",
        "  plot_image_with_overlay(image_slice, prediction=prediction)\n",
        "  \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "12U2HT9KcCvA"
      },
      "source": [
        "## Plot ground truth"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CSMdcmQh2uBV"
      },
      "source": [
        "def plot_ground_truth(image, lesions, patient_id):\n",
        "  title = f'Slice for patient {patient_id}'\n",
        "  fig = plt.figure(figsize=(15, 15))\n",
        "  ax = fig.add_subplot(1, 3, 1)\n",
        "  ax.set_title(f'Original: {title}')\n",
        "  plt.imshow(image, cmap='gray', interpolation=None)\n",
        "  ax = fig.add_subplot(1, 3, 2)\n",
        "  ax.set_title(f'MPL: {title}')\n",
        "  for lesion in lesions:\n",
        "    ax.add_patch(patches.Polygon(lesion.points, closed=True,\n",
        "                                 color=ARTERIES[lesion.artery].color))\n",
        "  ax.imshow(image, cmap='gray', interpolation=None)\n",
        "  ax = fig.add_subplot(1, 3, 3)\n",
        "  ax.set_title(f'Mask: {title}')\n",
        "  mask = create_mask(image, lesions)\n",
        "  if not lesions:\n",
        "    assert np.sum(mask) < 0.000001, f'Bad mask'\n",
        "  plt.imshow(mask, cmap='gray', interpolation=None)\n",
        "\n",
        "def sample_images(df, split, num_positives, num_negatives, shuffle=False):\n",
        "  if shuffle:\n",
        "    df = df.sample(frac=1, random_state=1216)\n",
        "  positives = df.loc[(df.patient_split == split) & (df.has_calcification==True)].image_path[0:num_positives]\n",
        "  negatives = df.loc[(df.patient_split == split) & (df.has_calcification==False)].image_path[0:num_negatives]\n",
        "  return pd.concat([positives, negatives])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lm9g4eSbLVnH"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tcYF_-5JfiAM"
      },
      "source": [
        "##Define generator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z0adVUHHMjVy"
      },
      "source": [
        "def create_mask(image: np.ndarray, lesions: List[Lesion]):\n",
        "  height, width = image.shape\n",
        "  if not lesions:\n",
        "    return np.zeros((height, width), dtype=np.float32)\n",
        "  all_bool_masks = []\n",
        "  for lesion in lesions:\n",
        "    lesion_points = [(p[1], p[0]) for p in lesion.points]\n",
        "    poly_path = Path(lesion_points)\n",
        "    x, y = np.mgrid[:height, :width]\n",
        "    coordinates = np.hstack((x.reshape(-1,1), y.reshape(-1,1)))\n",
        "    bool_mask = poly_path.contains_points(coordinates).reshape(height, width)\n",
        "    all_bool_masks.append(bool_mask)\n",
        "  out_mask = np.zeros((height, width))\n",
        "  for mask in all_bool_masks:\n",
        "    out_mask += mask\n",
        "  return out_mask.astype(np.float32)\n",
        "\n",
        "def normalize_image(image: np.ndarray):\n",
        "  \"\"\"Normalize pixels to the range [0, 1].\"\"\"\n",
        "  image_min = np.min(image)\n",
        "  image_range = np.max(image) - image_min\n",
        "  return ((image - image_min)/ image_range).astype(np.float32)\n",
        "\n",
        "def load_single_example(image_path, image_df, gated_dir): \n",
        "  assert image_df.image_path.nunique() == 1\n",
        "  full_image_path = os.path.join(gated_dir, image_path[1:])\n",
        "  image = pydicom.dcmread(full_image_path).pixel_array\n",
        "  image = normalize_image(image)\n",
        "  lesions = []\n",
        "  for _, lesion_row in image_df.iterrows():\n",
        "    if isinstance(lesion_row.lesion_points, float):\n",
        "      # No lesions for this image\n",
        "      continue\n",
        "    lesions.append(Lesion(\n",
        "        artery=lesion_row.artery,\n",
        "        points = lesion_row.lesion_points))\n",
        "  mask = create_mask(image, lesions)\n",
        "  assert image_df.patient_id.nunique() == 1\n",
        "  assert image_df.patient_split.nunique() == 1\n",
        "  assert image_df.has_calcification.nunique() == 1\n",
        "  return Slice(\n",
        "      patient_id = image_df.iloc[0].patient_id,\n",
        "      image_path = image_path,\n",
        "      patient_split = image_df.iloc[0].patient_split,\n",
        "      has_calcification = image_df.iloc[0].has_calcification,\n",
        "      lesions = lesions,\n",
        "      image = image,\n",
        "      ground_truth_mask = mask\n",
        "  )\n",
        "\n",
        "class DataGenerator(tf.keras.utils.Sequence):\n",
        "  def __init__(self,\n",
        "               df: pd.DataFrame,\n",
        "               name: Text,\n",
        "               image_paths: List[Text],\n",
        "               batch_size: int,\n",
        "               gated_dir: Text,\n",
        "               positive_upsample_factor,\n",
        "               add_dim: bool = False):\n",
        "    self.df = df\n",
        "    self.name = name\n",
        "    self.batch_size = batch_size\n",
        "    self.gated_dir = gated_dir\n",
        "    self.add_dim = add_dim\n",
        "    if positive_upsample_factor:\n",
        "      original_length = len(image_paths)\n",
        "      positive_image_paths = set(df.loc[(df.image_path.isin(image_paths)) & (df.has_calcification == True)].image_path)\n",
        "      upsampled_positive_image_paths = list(positive_image_paths) * positive_upsample_factor\n",
        "      image_paths = image_paths + upsampled_positive_image_paths\n",
        "      additional_images = len(image_paths)-original_length\n",
        "      print(f'Added {additional_images} images from {len(positive_image_paths)} original positives')\n",
        "    else:\n",
        "      print(f'No upsampling for {name}')\n",
        "    np.random.shuffle(image_paths)\n",
        "    self.image_paths = image_paths\n",
        "    \n",
        "  def __len__(self):\n",
        "    length = math.ceil(len(self.image_paths) / self.batch_size)\n",
        "    print(f'For {self.name} datagen length is {length}')\n",
        "    return length\n",
        "\n",
        "  def _prepare_batch(self, df, gated_dir): # TODO: rename to batch_df\n",
        "    X_list = []\n",
        "    Y_list = []\n",
        "    grouped_df = df.groupby('image_path')\n",
        "    for i, (image_path, image_df) in enumerate(grouped_df):\n",
        "      image_slice = load_single_example(image_path, image_df, gated_dir) \n",
        "      if self.add_dim:\n",
        "        X_list.append(np.expand_dims(image_slice.image, axis=2))\n",
        "      else:\n",
        "        X_list.append(image_slice.image)\n",
        "      Y_list.append(image_slice.ground_truth_mask)\n",
        "    X = np.array(X_list)\n",
        "    Y = np.array(Y_list)\n",
        "    return X, Y\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    batch_image_paths = self.image_paths[idx * self.batch_size: (idx+1) * self.batch_size]\n",
        "    batch_metadata_df = self.df[self.df.image_path.isin(batch_image_paths)]\n",
        "    X, Y = self._prepare_batch(batch_metadata_df, self.gated_dir)\n",
        "    return X, Y\n",
        "\n",
        "  def on_epoch_end(self):\n",
        "    np.random.shuffle(self.image_paths)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PnNaF2N6LZtQ"
      },
      "source": [
        "## Define model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F7-Ptu-v_iiR"
      },
      "source": [
        "### U-Net"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VZXH78xokxyk"
      },
      "source": [
        "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Dense, Flatten, Dropout, BatchNormalization, Activation, Conv2DTranspose\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras import backend as K\n",
        "import tensorflow.keras.layers as layers\n",
        "\n",
        "def get_unet(dropout=None, batch_norm=False):\n",
        "\n",
        "  def conv2d_block(input_tensor, n_filters, kernel_size=3):\n",
        "    # TODO: revisit default kernel size.\n",
        "    \"\"\"Function to add 2 convolutional layers.\"\"\"\n",
        "    # first layer\n",
        "    x = Conv2D(filters=n_filters, kernel_size=(kernel_size, kernel_size),\n",
        "                kernel_initializer='he_normal', padding='same')(input_tensor)\n",
        "    if batch_norm:\n",
        "        x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "    if dropout:\n",
        "        x = Dropout(dropout)(x)\n",
        "\n",
        "    # second layer\n",
        "    x = Conv2D(filters=n_filters, kernel_size=(kernel_size, kernel_size),\n",
        "                kernel_initializer='he_normal', padding='same')(x)\n",
        "    if batch_norm:\n",
        "        x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "    if dropout:\n",
        "        x = Dropout(dropout)(x)\n",
        "    return x\n",
        "\n",
        "  inputs = Input(shape=(512, 512, 1))\n",
        "\n",
        "  # Encoder path\n",
        "  # Conv2D-64 (3x3, same) -> 512x512x64 -> maxpool -> 256x256x64\n",
        "  c1 = conv2d_block(inputs, 64)\n",
        "  p1 = MaxPooling2D(pool_size=(2,2), strides=(2,2))(c1)\n",
        "  # if dropout:\n",
        "  #     p1 = Dropout(dropout)(p1)\n",
        "\n",
        "  # # Conv2D-128 (3x3, same) -> 256x256x128 -> maxpool -> 128x128x128\n",
        "  c2 = conv2d_block(p1, 128)\n",
        "  p2 = MaxPooling2D(pool_size=(2,2), strides=(2,2))(c2)\n",
        "  # if dropout:\n",
        "  #     p2 = Dropout(dropout)(p2)\n",
        "\n",
        "  # # Conv2D-256 (3x3, same) -> 128x128x128 -> maxpool -> 64x64x256\n",
        "  c3 = conv2d_block(p2, 256)\n",
        "  p3 = MaxPooling2D(pool_size=(2,2), strides=(2,2))(c3)\n",
        "  # if dropout:\n",
        "  #     p3 = Dropout(dropout)(p3)\n",
        "\n",
        "  # # Conv2D-512 (3x3, same) -> 64x64x256 -> maxpool -> 32x32x512\n",
        "  c4 = conv2d_block(p3, 512)\n",
        "  p4 = MaxPooling2D(pool_size=(2, 2), strides=(2,2))(c4)\n",
        "  # if dropout:\n",
        "  #     p4 = Dropout(dropout)(p4)\n",
        "\n",
        "  # # Conv2D-512 (3x3, same) -> 32x32x1024\n",
        "  c5 = conv2d_block(p4, 1024)\n",
        "  p5 = c5\n",
        "  # if dropout:\n",
        "  #     p5 = Dropout(dropout)(p5)\n",
        "\n",
        "  # # Decoder path (64x64)\n",
        "  u4 = Conv2DTranspose(512, (3, 3), strides=(2, 2), padding='same')(p5)\n",
        "  u4 = layers.concatenate([u4, c4])\n",
        "  # if dropout:\n",
        "  #     u4 = Dropout(dropout)(u4)\n",
        "  u4 = conv2d_block(u4, 512)\n",
        "\n",
        "  # # 128x128\n",
        "  u3 = Conv2DTranspose(256, (3, 3), strides=(2, 2), padding='same')(u4)\n",
        "  u3 = layers.concatenate([u3, c3])\n",
        "  # if dropout:\n",
        "  #     u3 = Dropout(dropout)(u3)\n",
        "  u3 = conv2d_block(u3, 256)\n",
        "\n",
        "  # # 256x256\n",
        "  u2 = Conv2DTranspose(128, (3, 3), strides=(2, 2), padding='same')(u3)\n",
        "  u2 = layers.concatenate([u2, c2])\n",
        "  # if dropout:\n",
        "  #     u2 = Dropout(dropout)(u2)\n",
        "  u2 = conv2d_block(u2, 128)\n",
        "\n",
        "  # # 512x512\n",
        "  u1 = Conv2DTranspose(64, (3, 3), strides=(2, 2), padding='same')(u2)\n",
        "  u1 = layers.concatenate([u1, c1])\n",
        "  # if dropout:\n",
        "  #     u1 = Dropout(dropout)(u1)\n",
        "  u1 = conv2d_block(u1, 64)\n",
        "  outputs = Conv2D(1, kernel_size=(1, 1), activation=\"sigmoid\")(u1)\n",
        "\n",
        "  model = Model(inputs=inputs, outputs=outputs)\n",
        "  print(type(model))\n",
        "  return model\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "meAk9G3luz9N"
      },
      "source": [
        "### Attention U-Net"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "seNTm2QHu1PP"
      },
      "source": [
        "from keras.layers import Activation, add, multiply, Lambda\n",
        "from keras.layers import AveragePooling2D, average, UpSampling2D, Dropout\n",
        "from keras.layers import Input, concatenate, Conv2D, MaxPooling2D, Conv2DTranspose\n",
        "from keras.initializers import glorot_normal\n",
        "\n",
        "# From https://github.com/nabsabraham/focal-tversky-unet\n",
        "\n",
        "# K.set_image_data_format('channels_last')  # TF dimension ordering in this code\n",
        "kinit = 'glorot_normal'\n",
        "\n",
        "def expend_as(tensor, rep,name):\n",
        "\tmy_repeat = Lambda(lambda x, repnum: K.repeat_elements(x, repnum, axis=3), arguments={'repnum': rep},  name='psi_up'+name)(tensor)\n",
        "\treturn my_repeat\n",
        "\n",
        "def UnetConv2D(input, outdim, is_batchnorm, name):\n",
        "\tx = Conv2D(outdim, (3, 3), strides=(1, 1), kernel_initializer=kinit, padding=\"same\", name=name+'_1')(input)\n",
        "\tif is_batchnorm:\n",
        "\t\tx =BatchNormalization(name=name + '_1_bn')(x)\n",
        "\tx = Activation('relu',name=name + '_1_act')(x)\n",
        "\n",
        "\tx = Conv2D(outdim, (3, 3), strides=(1, 1), kernel_initializer=kinit, padding=\"same\", name=name+'_2')(x)\n",
        "\tif is_batchnorm:\n",
        "\t\tx = BatchNormalization(name=name + '_2_bn')(x)\n",
        "\tx = Activation('relu', name=name + '_2_act')(x)\n",
        "\treturn x\n",
        "\n",
        "def UnetGatingSignal(input, is_batchnorm, name):\n",
        "  shape = K.int_shape(input)\n",
        "  x = Conv2D(shape[3] * 1, (1, 1), strides=(1, 1), padding=\"same\",  kernel_initializer=kinit, name=name + '_conv')(input)\n",
        "  if is_batchnorm:\n",
        "      x = BatchNormalization(name=name + '_bn')(x)\n",
        "  x = Activation('relu', name = name + '_act')(x)\n",
        "  return x\n",
        "\n",
        "\n",
        "def AttnGatingBlock(x, g, inter_shape, name, dropout_block):\n",
        "  shape_x = K.int_shape(x)  # 32\n",
        "  shape_g = K.int_shape(g)  # 16\n",
        "\n",
        "  theta_x = Conv2D(inter_shape, (2, 2), strides=(2, 2), padding='same', name='xl'+name)(x)  # 16\n",
        "  shape_theta_x = K.int_shape(theta_x)\n",
        "\n",
        "  phi_g = Conv2D(inter_shape, (1, 1), padding='same')(g)\n",
        "  upsample_g = Conv2DTranspose(inter_shape, (3, 3),strides=(shape_theta_x[1] // shape_g[1], shape_theta_x[2] // shape_g[2]),padding='same', name='g_up'+name)(phi_g)  # 16\n",
        "\n",
        "  concat_xg = add([upsample_g, theta_x])\n",
        "  act_xg = Activation('relu')(concat_xg)\n",
        "  if dropout_block:\n",
        "    act_xg = Dropout(dropout_block, name='drop_psi'+name)(act_xg)\n",
        "  psi = Conv2D(1, (1, 1), padding='same', name='psi'+name)(act_xg)\n",
        "  sigmoid_xg = Activation('sigmoid')(psi)\n",
        "  shape_sigmoid = K.int_shape(sigmoid_xg)\n",
        "  upsample_psi = UpSampling2D(size=(shape_x[1] // shape_sigmoid[1], shape_x[2] // shape_sigmoid[2]))(sigmoid_xg)  # 32\n",
        "\n",
        "  upsample_psi = expend_as(upsample_psi, shape_x[3],  name)\n",
        "  y = multiply([upsample_psi, x], name='q_attn'+name)\n",
        "\n",
        "  result = Conv2D(shape_x[3], (1, 1), padding='same',name='q_attn_conv'+name)(y)\n",
        "  result_bn = BatchNormalization(name='q_attn_bn'+name)(result)\n",
        "  return result_bn\n",
        "\n",
        "def get_attn_unet(dropout_rate, dropout_block, input_size=(512, 512, 1)):   \n",
        "    # New: adds dropout to the attention gating block before the linear layer.\n",
        "    inputs = Input(shape=input_size)\n",
        "    conv1 = UnetConv2D(inputs, 32, is_batchnorm=True, name='conv1')\n",
        "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
        "    \n",
        "    conv2 = UnetConv2D(pool1, 32, is_batchnorm=True, name='conv2')\n",
        "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
        "\n",
        "    conv3 = UnetConv2D(pool2, 64, is_batchnorm=True, name='conv3')\n",
        "    if dropout_rate:\n",
        "      conv3 = Dropout(dropout_rate,name='drop_conv3')(conv3)\n",
        "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
        "\n",
        "    conv4 = UnetConv2D(pool3, 64, is_batchnorm=True, name='conv4')\n",
        "    if dropout_rate:\n",
        "      conv4 = Dropout(dropout_rate, name='drop_conv4')(conv4)\n",
        "    pool4 = MaxPooling2D(pool_size=(2, 2))(conv4)\n",
        "    \n",
        "    center = UnetConv2D(pool4, 128, is_batchnorm=True, name='center')\n",
        "    \n",
        "    g1 = UnetGatingSignal(center, is_batchnorm=True, name='g1')\n",
        "    attn1 = AttnGatingBlock(conv4, g1, 128, '_1', dropout_block)\n",
        "    up1 = concatenate([Conv2DTranspose(32, (3,3), strides=(2,2), padding='same', activation='relu', kernel_initializer=kinit)(center), attn1], name='up1')\n",
        "    \n",
        "    g2 = UnetGatingSignal(up1, is_batchnorm=True, name='g2')\n",
        "    attn2 = AttnGatingBlock(conv3, g2, 64, '_2', dropout_block)\n",
        "    up2 = concatenate([Conv2DTranspose(64, (3,3), strides=(2,2), padding='same', activation='relu', kernel_initializer=kinit)(up1), attn2], name='up2')\n",
        "\n",
        "    g3 = UnetGatingSignal(up1, is_batchnorm=True, name='g3')\n",
        "    attn3 = AttnGatingBlock(conv2, g3, 32, '_3', dropout_block)\n",
        "    up3 = concatenate([Conv2DTranspose(32, (3,3), strides=(2,2), padding='same', activation='relu', kernel_initializer=kinit)(up2), attn3], name='up3')\n",
        "\n",
        "    up4 = concatenate([Conv2DTranspose(32, (3,3), strides=(2,2), padding='same', activation='relu', kernel_initializer=kinit)(up3), conv1], name='up4')\n",
        "    out = Conv2D(1, (1, 1), activation='sigmoid',  kernel_initializer=kinit, name='final')(up4)\n",
        "    \n",
        "    model = Model(inputs=[inputs], outputs=[out])\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VNRFgdNS_pcL"
      },
      "source": [
        "### Reza-Net"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lHH1dRIP1NPE"
      },
      "source": [
        "# From https://github.com/rezazad68/BCDU-Net\n",
        "from keras.layers import Input, concatenate, Conv2D, MaxPooling2D, UpSampling2D, Reshape, core, Dropout\n",
        "from keras.layers import ConvLSTM2D\n",
        "    \n",
        "def get_reza_net(input_size = (512, 512, 1)):\n",
        "    N = input_size[0]\n",
        "    inputs = Input(input_size) \n",
        "    conv1 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(inputs)\n",
        "    conv1 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv1)\n",
        "  \n",
        "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
        "    conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool1)\n",
        "    conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv2)\n",
        "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
        "    conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool2)\n",
        "    conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv3)\n",
        "    drop3 = Dropout(0.5)(conv3)\n",
        "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
        "    # D1\n",
        "    conv4 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool3)     \n",
        "    conv4_1 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv4)\n",
        "    drop4_1 = Dropout(0.5)(conv4_1)\n",
        "    # D2\n",
        "    conv4_2 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(drop4_1)     \n",
        "    conv4_2 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv4_2)\n",
        "    conv4_2 = Dropout(0.5)(conv4_2)\n",
        "    # D3\n",
        "    merge_dense = concatenate([conv4_2,drop4_1], axis = 3)\n",
        "    conv4_3 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge_dense)     \n",
        "    conv4_3 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv4_3)\n",
        "    drop4_3 = Dropout(0.5)(conv4_3)\n",
        "    \n",
        "    up6 = Conv2DTranspose(256, kernel_size=2, strides=2, padding='same',kernel_initializer = 'he_normal')(drop4_3)\n",
        "    up6 = BatchNormalization(axis=3)(up6)\n",
        "    up6 = Activation('relu')(up6)\n",
        "\n",
        "    x1 = Reshape(target_shape=(1, np.int32(N/4), np.int32(N/4), 256))(drop3)\n",
        "    x2 = Reshape(target_shape=(1, np.int32(N/4), np.int32(N/4), 256))(up6)\n",
        "    merge6  = concatenate([x1,x2], axis = 1) \n",
        "    merge6 = ConvLSTM2D(filters = 128, kernel_size=(3, 3), padding='same', return_sequences = False, go_backwards = True,kernel_initializer = 'he_normal' )(merge6)\n",
        "            \n",
        "    conv6 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge6)\n",
        "    conv6 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv6)\n",
        "\n",
        "    up7 = Conv2DTranspose(128, kernel_size=2, strides=2, padding='same',kernel_initializer = 'he_normal')(conv6)\n",
        "    up7 = BatchNormalization(axis=3)(up7)\n",
        "    up7 = Activation('relu')(up7)\n",
        "\n",
        "    x1 = Reshape(target_shape=(1, np.int32(N/2), np.int32(N/2), 128))(conv2)\n",
        "    x2 = Reshape(target_shape=(1, np.int32(N/2), np.int32(N/2), 128))(up7)\n",
        "    merge7  = concatenate([x1,x2], axis = 1) \n",
        "    merge7 = ConvLSTM2D(filters = 64, kernel_size=(3, 3), padding='same', return_sequences = False, go_backwards = True,kernel_initializer = 'he_normal' )(merge7)\n",
        "        \n",
        "    conv7 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge7)\n",
        "    conv7 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv7)\n",
        "\n",
        "    up8 = Conv2DTranspose(64, kernel_size=2, strides=2, padding='same',kernel_initializer = 'he_normal')(conv7)\n",
        "    up8 = BatchNormalization(axis=3)(up8)\n",
        "    up8 = Activation('relu')(up8)    \n",
        "\n",
        "    x1 = Reshape(target_shape=(1, N, N, 64))(conv1)\n",
        "    x2 = Reshape(target_shape=(1, N, N, 64))(up8)\n",
        "    merge8  = concatenate([x1,x2], axis = 1) \n",
        "    merge8 = ConvLSTM2D(filters = 32, kernel_size=(3, 3), padding='same', return_sequences = False, go_backwards = True,kernel_initializer = 'he_normal' )(merge8)    \n",
        "    \n",
        "    conv8 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge8)\n",
        "    conv8 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv8)\n",
        "    conv8 = Conv2D(2, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv8)\n",
        "    conv9 = Conv2D(1, 1, activation = 'sigmoid')(conv8)\n",
        "\n",
        "    model = Model(inputs, conv9)\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xt25Tnp58322"
      },
      "source": [
        "## Define custom callbacks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zONqgb46847X"
      },
      "source": [
        "def get_time():\n",
        "    return datetime.datetime.now(pytz.timezone('US/Pacific'))\n",
        "\n",
        "def get_time_str():\n",
        "    return get_time().strftime(\"%m-%d-%H:%M\")\n",
        "\n",
        "def get_str_from_time(time):\n",
        "    return time.strftime(\"%m-%d-%H:%M\")\n",
        "\n",
        "def get_duration_sec(first: datetime.datetime, second: datetime.datetime):\n",
        "  return (second - first).seconds\n",
        "\n",
        "class SaveMetricsCallback(keras.callbacks.Callback):\n",
        "  def __init__(self, metrics_file_prefix, save_frequency_steps):\n",
        "    self.epoch_path = f'{metrics_file_prefix}.epochs.csv'\n",
        "    self.step_path = f'{metrics_file_prefix}.steps.csv'\n",
        "    self.save_frequency_steps = save_frequency_steps\n",
        "    logging.info(f'Writing metrics to\\n{self.epoch_path}\\n{self.step_path}')\n",
        "  \n",
        "  def process(self, unit_name, unit_amount, logs, metrics_path):\n",
        "    pd_logs = collections.defaultdict(list)\n",
        "    pd_logs['time'] = get_time_str()\n",
        "    pd_logs[unit_name].append(unit_amount)\n",
        "    for metric, val in logs.items():\n",
        "      pd_logs[metric].append(val)\n",
        "    logs_df = pd.DataFrame(pd_logs)\n",
        "    with open(metrics_path, 'a') as f:\n",
        "      if unit_amount == 0:\n",
        "        logs_df.to_csv(f, mode='a', header=True)\n",
        "      else:\n",
        "        logs_df.to_csv(f, mode='a', header=False)\n",
        "\n",
        "  def on_epoch_end(self, epoch, logs=None):\n",
        "    logging.info(f'Logging epoch {epoch}')\n",
        "    self.process('epoch', epoch, logs=logs,\n",
        "            metrics_path=self.epoch_path)\n",
        "\n",
        "  def on_train_batch_end(self, batch, logs=None):\n",
        "    if batch % self.save_frequency_steps == 0:\n",
        "      time_start = get_time()\n",
        "      self.process('step', batch, logs=logs,\n",
        "              metrics_path=self.step_path)\n",
        "      logging.info(f'Took {get_duration_sec(time_start, get_time())} seconds to record batch metrics')\n",
        "\n",
        "class SaveCheckpointCallback(keras.callbacks.Callback):\n",
        "  def __init__(self, save_frequency_steps, checkpoint_dir):\n",
        "    self.save_frequency_steps = save_frequency_steps\n",
        "    self.checkpoint_dir = checkpoint_dir\n",
        "    if not os.path.exists(checkpoint_dir):\n",
        "      os.makedirs(checkpoints_dir)\n",
        "    logging.info(f'Saving checkpoints to {self.checkpoint_dir}')\n",
        "\n",
        "  def on_train_batch_end(self, batch, logs=None):\n",
        "    if batch % self.save_frequency_steps == 0:\n",
        "      start_time = get_time()\n",
        "      out_path = os.path.join(self.checkpoint_dir, f'{get_str_from_time(start_time)}_step_{batch}.hf5')\n",
        "      tf.keras.models.save_model(self.model, filepath=out_path)\n",
        "      logging.info(f'Took {get_duration_sec(start_time, get_time())} seconds to save checkpoint')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uzsow5NEUlyx"
      },
      "source": [
        "## Define loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7W1M7EAAUmeO"
      },
      "source": [
        "def dice_coef(y_true, y_pred, smooth=1e-8):\n",
        "  y_true_f = K.flatten(y_true)\n",
        "  y_pred_f = K.flatten(y_pred)\n",
        "  intersection = K.sum(y_true_f * y_pred_f)\n",
        "  denom = K.sum(K.square(y_true_f)) + K.sum(K.square(y_pred_f))\n",
        "  dice = (2 * intersection + smooth) / (denom + smooth)\n",
        "  return dice\n",
        "\n",
        "def dice_loss(y_true, y_pred):\n",
        "  return 1.0 - dice_coef(y_true, y_pred)\n",
        "\n",
        "def focal_loss(y_true, y_pred):\n",
        "  alpha = 0.55\n",
        "  gamma = 2.\n",
        "  y_true_f = K.flatten(y_true)\n",
        "  y_pred_f = K.flatten(y_pred)\n",
        "  focal = tfa.losses.SigmoidFocalCrossEntropy(reduction=tf.keras.losses.Reduction.NONE,\n",
        "                                              gamma=gamma,\n",
        "                                              alpha=alpha)(y_true_f, y_pred_f)\n",
        "  return K.sum(focal)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MM-YCD70d3Sd"
      },
      "source": [
        "## Actually train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6V0e07sOpzhh"
      },
      "source": [
        "#### Resume saved model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qtXc2vUG81XC"
      },
      "source": [
        "SAVED_MODELS = {\n",
        "  'upsample_dice_resume': '2021-11-26-01:58.upsample_dice_resume/08.hf5',\n",
        "  'focal': '2021-11-27-02:37.final_unet_real_focal/11-28-01:31_step_11500.hf5',\n",
        "  'focal_attention': '2021-11-29-00:09.attn_gate_focal/11-29-08:57_step_0.hf5',\n",
        "}\n",
        "\n",
        "CUSTOM_OBJECTS = {'dice_loss': dice_loss, 'dice_coef': dice_coef, 'focal_loss': focal_loss}\n",
        "\n",
        "def load_model(fname, project_base_dir, custom_objects=CUSTOM_OBJECTS):\n",
        "  fpath = os.path.join(project_base_dir, 'checkpoints', fname)\n",
        "  saved_model = keras.models.load_model(fpath, custom_objects=custom_objects)\n",
        "  return saved_model\n",
        "\n",
        "focal_vanilla_model = load_model(\n",
        "    SAVED_MODELS['focal'],\n",
        "    project_base_dir\n",
        ")\n",
        "\n",
        "upsample_dice_model = load_model(\n",
        "    SAVED_MODELS['upsample_dice_resume'],\n",
        "    project_base_dir\n",
        ")\n",
        "\n",
        "focal_attention_model = load_model(\n",
        "    SAVED_MODELS['focal_attention'],\n",
        "    project_base_dir\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fr9a6CSwoWYe"
      },
      "source": [
        "model_prefix = 'attn_gate_focal' #@param{type:'string'}\n",
        "epochs =  30#@param{type:'number'}\n",
        "train_batch_size =   8#@param{type:'number'}\n",
        "tune_batch_size =   8#@param{type:'number'}\n",
        "current_time = datetime.datetime.now(pytz.timezone('US/Pacific')).strftime(\"%Y-%m-%d-%H:%M\")\n",
        "train_positive_upsample_factor =  7#@param{type:'number'}\n",
        "metric_save_frequency = 2500 #@param{type:'number'}\n",
        "checkpoint_save_frequency =  2500#@param{type:'number'}\n",
        "dropout_rate = 0.2 #@param{type:'number'}\n",
        "# Originally 0.0001\n",
        "learning_rate = 0.001 #@param{type:'number'} \n",
        "add_dim = True #@param{type:'boolean'}\n",
        "resume_training = False #@param{type:'boolean'}\n",
        "\n",
        "init_checkpoint_path = os.path.join(project_base_dir, 'checkpoints/2021-11-26-01:58.upsample_dice_resume/06.hf5')\n",
        "\n",
        "metrics_file_prefix = os.path.join(project_base_dir, 'experiment_metrics', f'{current_time}.{model_prefix}', f'{current_time}.{model_prefix}') \n",
        "checkpoints_dir = os.path.join(project_base_dir, 'checkpoints', f'{current_time}.{model_prefix}')\n",
        "checkpoint_path = os.path.join(checkpoints_dir, f'{model_prefix}_{current_time}.h5')\n",
        "\n",
        "if not os.path.exists(os.path.dirname(metrics_file_prefix)):\n",
        "  os.makedirs(os.path.dirname(metrics_file_prefix))\n",
        "if not os.path.exists(checkpoints_dir):\n",
        "  os.mkdir(checkpoints_dir)\n",
        "else:\n",
        "  raise ValueError(f'Checkpoint dir {checkpoints_dir} already exists')\n",
        "\n",
        "model = get_attn_unet(dropout_rate=dropout_rate, dropout_block=dropout_rate)\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
        "              loss=focal_loss,\n",
        "              metrics=['accuracy', \n",
        "                        dice_coef,\n",
        "                      ])\n",
        "print(f'Starting at {current_time}')\n",
        "print(f'Writing checkpoint to {checkpoint_path}')\n",
        "\n",
        "def lr_scheduler(epoch, lr):\n",
        "  if epoch < 5:\n",
        "    return 1e-3\n",
        "  return 0.0005\n",
        "\n",
        "history = model.fit(\n",
        "    # initial_epoch=8, # TODO: get rid\n",
        "    x=DataGenerator(\n",
        "        name='train',\n",
        "        df=df,\n",
        "        image_paths=train_image_paths, #[0:32],\n",
        "        batch_size=train_batch_size,\n",
        "        gated_dir=gated_dir,\n",
        "        positive_upsample_factor=train_positive_upsample_factor,\n",
        "        add_dim=add_dim),\n",
        "    epochs=epochs,\n",
        "    validation_data=DataGenerator(\n",
        "        name='tune',\n",
        "        df=df,\n",
        "        image_paths=tune_image_paths, #[0:32],\n",
        "        batch_size=tune_batch_size,\n",
        "        gated_dir=gated_dir,\n",
        "        positive_upsample_factor=0,\n",
        "        add_dim=add_dim),\n",
        "    callbacks=[\n",
        "      SaveMetricsCallback(metrics_file_prefix,\n",
        "                          save_frequency_steps=metric_save_frequency),\n",
        "      SaveCheckpointCallback(save_frequency_steps=checkpoint_save_frequency,\n",
        "                             checkpoint_dir=checkpoints_dir),\n",
        "      tf.keras.callbacks.LearningRateScheduler(lr_scheduler),          \n",
        "    ],\n",
        "    verbose=1,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tra5D7mzsmYQ"
      },
      "source": [
        "## Evaluate model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GJhw8UNkRoxP"
      },
      "source": [
        "test_results = focal_attention_model.evaluate(\n",
        "    x=DataGenerator(\n",
        "        name='test',\n",
        "        df=df,\n",
        "        image_paths=test_image_paths,\n",
        "        batch_size=32,\n",
        "        gated_dir=gated_dir,\n",
        "        positive_upsample_factor=0,\n",
        "        add_dim=True),\n",
        "    verbose=1,\n",
        "    return_dict=True,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ttEEVlusp5n"
      },
      "source": [
        "## Evaluate on single example"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jk3XWaxNsxeO"
      },
      "source": [
        "target_image = '/patient/401/Pro_Gated_Calcium_Score_(CS)_3.0_Qr36_2_BestDiast_72_%/IM-7084-0013.dcm'\n",
        "target_image = target_image\n",
        "image_df = df[df.image_path == target_image] \n",
        "example_slice = load_single_example(\n",
        "    image_path=target_image,\n",
        "    image_df=image_df,\n",
        "    gated_dir=gated_dir,\n",
        ")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XIxxShIn-itH"
      },
      "source": [
        "def prepare_input_image(image, expand_dims):\n",
        "  image = np.expand_dims(image, axis=0)\n",
        "  if expand_dims:\n",
        "    return np.expand_dims(image, axis=3)\n",
        "  else:\n",
        "    return np.expand_dims(image, axis=2)\n",
        "\n",
        "predictions = saved_reza(prepare_input_image(example_slice.image, True), training=False).numpy()\n",
        "predictions = np.squeeze(predictions)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FT3HQ8H9KRur"
      },
      "source": [
        "## Evaluate on batch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tc1zYvZ4LgDO"
      },
      "source": [
        "def get_prediction(saved_model, image, expand_dims=False):\n",
        "  image = np.expand_dims(image, axis=0)\n",
        "  if expand_dims:\n",
        "    image = np.expand_dims(image, axis=3)\n",
        "  prediction = saved_model(image, training=False).numpy()\n",
        "  # prediction = (prediction > 0.5).astype(np.float32)\n",
        "  return np.squeeze(prediction)\n",
        "\n",
        "\n",
        "def eval_batch(saved_model, expand_dims, evaluation_image_paths, df):\n",
        "  for image_path in evaluation_image_paths:\n",
        "    print(image_path)\n",
        "    image_df = df.loc[df.image_path == image_path]\n",
        "    image_slice = load_single_example(image_path, image_df, gated_dir)\n",
        "    prediction = get_prediction(saved_model, image_slice.image, expand_dims)\n",
        "    print(f'prediction sum {np.sum(prediction)} and gt sum {np.sum(image_slice.ground_truth_mask)}')\n",
        "    plot_image_slice(image_slice, prediction)\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fF1oB2Ols9qs"
      },
      "source": [
        "sampled_image_paths = sample_images(df, 'tune', num_positives=5, num_negatives=2, shuffle=False)\n",
        "eval_batch(saved_focal_unet, False, sampled_image_paths, df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3-eJyfOi2lYr"
      },
      "source": [
        "sampled_image_paths = sample_images(df, 'tune', num_positives=5, num_negatives=2, shuffle=False)\n",
        "eval_batch(saved_attn_net, True, sampled_image_paths, df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GZSEbeLWeXRT"
      },
      "source": [
        "## Compute tune set metrics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ewnnnmzEeyVd"
      },
      "source": [
        "tune_positives = list((df.loc[(df.has_calcification == True) & (df.patient_split == 'tune')]).image_path)[0:33]\n",
        "tune_negatives = list((df.loc[(df.has_calcification == False) & (df.patient_split == 'tune')]).image_path)[0:128]\n",
        "train_positives = list((df.loc[(df.has_calcification == True) & (df.patient_split == 'train')]).image_path)[0:33]\n",
        "train_negatives = list((df.loc[(df.has_calcification == False) & (df.patient_split == 'train')]).image_path)[0:33]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f1l2tnJxUoRT"
      },
      "source": [
        "# Agatston Bucketing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O2aG9R_THoTF"
      },
      "source": [
        "volume_scores_path = os.path.join(project_base_dir, 'agatston', 'FINAL_test_set_agststons_volume.csv')\n",
        "volume_scores = read_csv(volume_scores)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3rpHvgI_bN9q",
        "outputId": "aad834a7-265d-49a0-b8a8-2e464f928bac"
      },
      "source": [
        "volume_scores.image_gt_agatston.mean()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "197.78481012658227"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "985SJ7n3ca8T"
      },
      "source": [
        "fig = plt.figure()\n",
        "fig.suptitle('Distribution of Volume-Level Agatston Scores')\n",
        "ax = fig.add_subplot(1, 2, 1)\n",
        "ax.set_title('Ground Truth')\n",
        "ax.hist(list(volume_scores.image_gt_agatston))\n",
        "ax = fig.add_subplot(1, 2, 2)\n",
        "ax.set_title('Predicted')\n",
        "ax.hist(list(volume_scores.predicted_agatston))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I9uO6RDgHPG1"
      },
      "source": [
        "def bucket(score):\n",
        "  if score == 0:\n",
        "    return 0\n",
        "  if 1 <= score <= 10:\n",
        "    return 1\n",
        "  if 11 <= score <= 99:\n",
        "    return 2\n",
        "  if 100 <= score <= 300:\n",
        "    return 3\n",
        "  if 400 <= score <= 999:\n",
        "    return 4\n",
        "  return 5\n",
        "\n",
        "volume_scores['gt_bucket'] = volume_scores.image_gt_agatston.apply(bucket)\n",
        "volume_scores['predicted_bucket'] = volume_scores.predicted_agatston.apply(bucket)\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}