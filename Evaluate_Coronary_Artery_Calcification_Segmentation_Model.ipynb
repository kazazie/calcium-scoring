{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Evaluate Coronary Artery Calcification Segmentation Model",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uowz33rsz5bB"
      },
      "source": [
        "This colab qualitatively and quantitatively evaluates segmentation results. It produces the predicted segmentations on the tune and test sets and visualizes them.\n",
        "\n",
        "It then computes the Agatston coronary artery calcium scores from the ground truth and predicted segmentations, finds the best threshold from 0 to 1 on the tune set, and produces Agatston scores for the test sets.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GqHREB4m-1q2",
        "outputId": "31c08f79-e715-4a02-f906-15cc73f04931"
      },
      "source": [
        "!pip install pydicom\n",
        "\n",
        "import ast\n",
        "import collections\n",
        "import dataclasses\n",
        "import datetime\n",
        "import logging\n",
        "import math\n",
        "import matplotlib.patches as patches\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import pickle\n",
        "import numpy as np\n",
        "import os\n",
        "import plistlib\n",
        "import pydicom\n",
        "import pytz\n",
        "import sys\n",
        "import tensorflow as tf\n",
        "from matplotlib.path import Path\n",
        "from scipy.ndimage import measurements\n",
        "from tensorflow import keras\n",
        "from typing import Dict, List, Optional, Text, Tuple\n",
        "from tensorflow.python.client import device_lib\n",
        "from tensorflow.keras import backend as K\n",
        "\n",
        "logger = logging.getLogger()\n",
        "logger.setLevel(logging.DEBUG)\n",
        "\n",
        "project_base_dir = ''\n",
        "parsed_lesions_path = ''\n",
        "gated_dir = ''\n",
        "gt_agatston_file = ''"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pydicom\n",
            "  Downloading pydicom-2.2.2-py3-none-any.whl (2.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.0 MB 5.0 MB/s \n",
            "\u001b[?25hInstalling collected packages: pydicom\n",
            "Successfully installed pydicom-2.2.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B3bZnvgOBcEf"
      },
      "source": [
        "@dataclasses.dataclass\n",
        "class Artery:\n",
        "  name: Text\n",
        "  class_index: int\n",
        "  color: Text\n",
        "\n",
        "@dataclasses.dataclass\n",
        "class Lesion:\n",
        "  points: List[Tuple[float, float]]\n",
        "  artery: Text\n",
        "\n",
        "@dataclasses.dataclass\n",
        "class DicomAttributes:\n",
        "  pixel_spacing: Optional[Tuple[float]]\n",
        "  slice_thickness: Optional[float]\n",
        "  rescale_intercept: Optional[float]\n",
        "  rescale_slope: Optional[float]\n",
        "  \n",
        "@dataclasses.dataclass\n",
        "class Slice:\n",
        "  patient_id: Text\n",
        "  image_path: Text \n",
        "  patient_split: Text\n",
        "  has_calcification: bool\n",
        "  lesions: List[Lesion]\n",
        "  image: np.ndarray\n",
        "  ground_truth_mask: np.ndarray\n",
        "  dicom_attributes: DicomAttributes\n",
        "  raw_image: np.ndarray\n",
        "  ground_truth_agatston: Optional[float] = None\n",
        "  predicted_agatston: Optional[float] = None\n",
        "  predicted_mas: np.ndarray = None\n",
        "\n",
        "ARTERIES = {'Right Coronary Artery': Artery(\n",
        "                name='Right Coronary Artery',\n",
        "                class_index=0,\n",
        "                color='red',),\n",
        "            'Left Anterior Descending Artery': Artery(\n",
        "                name='Left Anterior Descending Artery',\n",
        "                class_index=1,\n",
        "                color='blue',),\n",
        "            'Left Coronary Artery': Artery(\n",
        "                name='Left Coronary Artery',\n",
        "                class_index=2,\n",
        "                color='green',),\n",
        "            'Left Circumflex Artery': Artery(\n",
        "                name='Left Circumflex artery',\n",
        "                class_index=3,\n",
        "                color='yellow',)\n",
        "            }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v_TfnsjD_8kx"
      },
      "source": [
        "def read_parsed_lesions(parsed_lesions_path):\n",
        "  BAD_PATIENT_IDS = set(\n",
        "    [78, 120, 146, 3336, 3309])\n",
        "  def maybe_literal_eval(x):\n",
        "    try:\n",
        "      return ast.literal_eval(x)\n",
        "    except:\n",
        "      return x\n",
        "\n",
        "  with open(parsed_lesions_path, 'r') as f:\n",
        "    df = pd.read_csv(f)\n",
        "  bad_row_indices = df.loc[df.patient_id.isin(BAD_PATIENT_IDS)].index\n",
        "  df = df.drop(index=bad_row_indices)\n",
        "  df['lesion_points'] = df.lesion_points.apply(maybe_literal_eval)\n",
        "  df = df.sample(frac=1, random_state=1216)\n",
        "  return df\n",
        "\n",
        "def read_csv(path):\n",
        "  with open(path, 'r') as f:\n",
        "    df = pd.read_csv(f)\n",
        "  return df\n",
        "\n",
        "def write_df(path, df):\n",
        "  if not os.path.exists(os.path.dirname(path)):\n",
        "    os.makedirs(os.path.dirname(path))\n",
        "  with open(path, 'w') as f:\n",
        "    df.to_csv(f, index=False)\n",
        "    print(f'Wrote file {path}')\n",
        "\n",
        "\n",
        "df = read_parsed_lesions(parsed_lesions_path)\n",
        "train_image_paths = list(df.loc[df.patient_split == 'train'].image_path.unique())\n",
        "tune_image_paths = list(df.loc[df.patient_split == 'tune'].image_path.unique())\n",
        "test_image_paths = list(df.loc[df.patient_split == 'test'].image_path.unique())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RrqYg1mGuJbB"
      },
      "source": [
        "# Agatston calculations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nI7kdNxyAVa-"
      },
      "source": [
        "def get_object_agatston(calc_object: np.ndarray, calc_pixel_count: int):\n",
        "  \"\"\"Applies standard categorization: https://radiopaedia.org/articles/agatston-score\"\"\"\n",
        "  object_max = np.max(calc_object)\n",
        "  object_agatston = 0\n",
        "  if 130 <= object_max < 200:\n",
        "    object_agatston = calc_pixel_count * 1\n",
        "  elif 200 <= object_max < 300:\n",
        "    object_agatston = calc_pixel_count * 2\n",
        "  elif 300 <= object_max < 400:\n",
        "    object_agatston = calc_pixel_count * 3\n",
        "  elif object_max >= 400:\n",
        "    object_agatston = calc_pixel_count * 4\n",
        "  # print(f'For {calc_pixel_count} with max {object_max} returning AG of {object_agatston}')\n",
        "  return object_agatston\n",
        "\n",
        "def compute_agatston_for_slice(example: Slice, predicted_mask: Optional[np.ndarray],\n",
        "                               min_calc_object_pixels = 3) -> int:\n",
        "  def create_hu_image(example: Slice):\n",
        "    dicom_attributes = example.dicom_attributes\n",
        "    if not dicom_attributes.rescale_slope or not dicom_attributes.rescale_intercept:\n",
        "      raise ValueError(f'Cannot convert {example.image_path} to Hounsfield units.')\n",
        "    return example.raw_image * dicom_attributes.rescale_slope + dicom_attributes.rescale_intercept\n",
        "  if not predicted_mask is None:\n",
        "    mask = predicted_mask\n",
        "  else:\n",
        "    mask = example.ground_truth_mask\n",
        "  if np.sum(mask) == 0:\n",
        "    return 0\n",
        "  slice_agatston = 0\n",
        "  dicom_attributes = example.dicom_attributes\n",
        "  pixel_volume = (dicom_attributes.pixel_spacing[0] * dicom_attributes.pixel_spacing[1])\n",
        "                 \n",
        "  hu_image = create_hu_image(example)\n",
        "  labeled_mask, num_labels = measurements.label(mask,\n",
        "                                                structure=np.ones((3, 3)))\n",
        "  for calc_idx in range(1, num_labels + 1):\n",
        "    label = np.zeros(mask.shape)\n",
        "    label[labeled_mask == calc_idx] = 1\n",
        "    calc_object = hu_image * label\n",
        "\n",
        "    calc_pixel_count = np.sum(label)\n",
        "    # Remove small calcified objects.\n",
        "    if calc_pixel_count <= min_calc_object_pixels:\n",
        "      continue\n",
        "    calc_volume = calc_pixel_count * pixel_volume\n",
        "    object_agatston = round(get_object_agatston(calc_object, calc_volume))\n",
        "    slice_agatston += object_agatston\n",
        "  return slice_agatston\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XKhzGREWZbHu"
      },
      "source": [
        "def sample_images(df, split, num_positives, num_negatives, shuffle=False):\n",
        "  if shuffle:\n",
        "    df = df.sample(frac=1, random_state=1216)\n",
        "  positives = df.loc[(df.patient_split == split) & (df.has_calcification==True)].image_path[0:num_positives]\n",
        "  negatives = df.loc[(df.patient_split == split) & (df.has_calcification==False)].image_path[0:num_negatives]\n",
        "  return pd.concat([positives, negatives])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nQTsgAkam6B7"
      },
      "source": [
        "# Load model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8FE4xFZhiHZO"
      },
      "source": [
        "def dice_coef(y_true, y_pred, smooth=1e-8):\n",
        "  y_true_f = K.flatten(y_true)\n",
        "  y_pred_f = K.flatten(y_pred)\n",
        "  intersection = K.sum(y_true_f * y_pred_f)\n",
        "  denom = K.sum(K.square(y_true_f)) + K.sum(K.square(y_pred_f))\n",
        "  dice = (2 * intersection + smooth) / (denom + smooth)\n",
        "  return dice\n",
        "\n",
        "def dice_loss(y_true, y_pred):\n",
        "  return 1.0 - dice_coef(y_true, y_pred)\n",
        "\n",
        "def focal_loss(y_true, y_pred):\n",
        "  alpha = 0.55\n",
        "  gamma = 2.\n",
        "  y_true_f = K.flatten(y_true)\n",
        "  y_pred_f = K.flatten(y_pred)\n",
        "  focal = tfa.losses.SigmoidFocalCrossEntropy(reduction=tf.keras.losses.Reduction.NONE,\n",
        "                                              gamma=gamma,\n",
        "                                              alpha=alpha)(y_true_f, y_pred_f)\n",
        "  return K.sum(focal)\n",
        "\n",
        "CUSTOM_OBJECTS = {'dice_loss': dice_loss, 'dice_coef': dice_coef, 'focal_loss': focal_loss}\n",
        "\n",
        "SAVED_MODELS = {\n",
        "  'upsample_dice_resume': '2021-11-26-01:58.upsample_dice_resume/08.hf5',\n",
        "  'focal': '2021-11-27-02:37.final_unet_real_focal/11-28-01:31_step_11500.hf5',\n",
        "  'focal_attention': '2021-11-29-00:09.attn_gate_focal/11-29-08:57_step_0.hf5',\n",
        "}\n",
        "\n",
        "def load_model(fname, project_base_dir, custom_objects=CUSTOM_OBJECTS):\n",
        "  fpath = os.path.join(project_base_dir, 'checkpoints', fname)\n",
        "  saved_model = keras.models.load_model(fpath, custom_objects=custom_objects)\n",
        "  return saved_model\n",
        "\n",
        "focal_attention_model = load_model(\n",
        "    SAVED_MODELS['focal_attention'],\n",
        "    project_base_dir\n",
        ")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O2qMK6ARKCEz",
        "outputId": "725c733e-cffe-4358-a5cf-a6e84a5a5ec8"
      },
      "source": [
        "focal_attention_model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_3\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_4 (InputLayer)           [(None, 512, 512, 1  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " conv1_1 (Conv2D)               (None, 512, 512, 32  320         ['input_4[0][0]']                \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv1_1_bn (BatchNormalization  (None, 512, 512, 32  128        ['conv1_1[0][0]']                \n",
            " )                              )                                                                 \n",
            "                                                                                                  \n",
            " conv1_1_act (Activation)       (None, 512, 512, 32  0           ['conv1_1_bn[0][0]']             \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv1_2 (Conv2D)               (None, 512, 512, 32  9248        ['conv1_1_act[0][0]']            \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv1_2_bn (BatchNormalization  (None, 512, 512, 32  128        ['conv1_2[0][0]']                \n",
            " )                              )                                                                 \n",
            "                                                                                                  \n",
            " conv1_2_act (Activation)       (None, 512, 512, 32  0           ['conv1_2_bn[0][0]']             \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " max_pooling2d_12 (MaxPooling2D  (None, 256, 256, 32  0          ['conv1_2_act[0][0]']            \n",
            " )                              )                                                                 \n",
            "                                                                                                  \n",
            " conv2_1 (Conv2D)               (None, 256, 256, 32  9248        ['max_pooling2d_12[0][0]']       \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2_1_bn (BatchNormalization  (None, 256, 256, 32  128        ['conv2_1[0][0]']                \n",
            " )                              )                                                                 \n",
            "                                                                                                  \n",
            " conv2_1_act (Activation)       (None, 256, 256, 32  0           ['conv2_1_bn[0][0]']             \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2_2 (Conv2D)               (None, 256, 256, 32  9248        ['conv2_1_act[0][0]']            \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2_2_bn (BatchNormalization  (None, 256, 256, 32  128        ['conv2_2[0][0]']                \n",
            " )                              )                                                                 \n",
            "                                                                                                  \n",
            " conv2_2_act (Activation)       (None, 256, 256, 32  0           ['conv2_2_bn[0][0]']             \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " max_pooling2d_13 (MaxPooling2D  (None, 128, 128, 32  0          ['conv2_2_act[0][0]']            \n",
            " )                              )                                                                 \n",
            "                                                                                                  \n",
            " conv3_1 (Conv2D)               (None, 128, 128, 64  18496       ['max_pooling2d_13[0][0]']       \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv3_1_bn (BatchNormalization  (None, 128, 128, 64  256        ['conv3_1[0][0]']                \n",
            " )                              )                                                                 \n",
            "                                                                                                  \n",
            " conv3_1_act (Activation)       (None, 128, 128, 64  0           ['conv3_1_bn[0][0]']             \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv3_2 (Conv2D)               (None, 128, 128, 64  36928       ['conv3_1_act[0][0]']            \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv3_2_bn (BatchNormalization  (None, 128, 128, 64  256        ['conv3_2[0][0]']                \n",
            " )                              )                                                                 \n",
            "                                                                                                  \n",
            " conv3_2_act (Activation)       (None, 128, 128, 64  0           ['conv3_2_bn[0][0]']             \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " drop_conv3 (Dropout)           (None, 128, 128, 64  0           ['conv3_2_act[0][0]']            \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " max_pooling2d_14 (MaxPooling2D  (None, 64, 64, 64)  0           ['drop_conv3[0][0]']             \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " conv4_1 (Conv2D)               (None, 64, 64, 64)   36928       ['max_pooling2d_14[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_1_bn (BatchNormalization  (None, 64, 64, 64)  256         ['conv4_1[0][0]']                \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " conv4_1_act (Activation)       (None, 64, 64, 64)   0           ['conv4_1_bn[0][0]']             \n",
            "                                                                                                  \n",
            " conv4_2 (Conv2D)               (None, 64, 64, 64)   36928       ['conv4_1_act[0][0]']            \n",
            "                                                                                                  \n",
            " conv4_2_bn (BatchNormalization  (None, 64, 64, 64)  256         ['conv4_2[0][0]']                \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " conv4_2_act (Activation)       (None, 64, 64, 64)   0           ['conv4_2_bn[0][0]']             \n",
            "                                                                                                  \n",
            " drop_conv4 (Dropout)           (None, 64, 64, 64)   0           ['conv4_2_act[0][0]']            \n",
            "                                                                                                  \n",
            " max_pooling2d_15 (MaxPooling2D  (None, 32, 32, 64)  0           ['drop_conv4[0][0]']             \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " center_1 (Conv2D)              (None, 32, 32, 128)  73856       ['max_pooling2d_15[0][0]']       \n",
            "                                                                                                  \n",
            " center_1_bn (BatchNormalizatio  (None, 32, 32, 128)  512        ['center_1[0][0]']               \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " center_1_act (Activation)      (None, 32, 32, 128)  0           ['center_1_bn[0][0]']            \n",
            "                                                                                                  \n",
            " center_2 (Conv2D)              (None, 32, 32, 128)  147584      ['center_1_act[0][0]']           \n",
            "                                                                                                  \n",
            " center_2_bn (BatchNormalizatio  (None, 32, 32, 128)  512        ['center_2[0][0]']               \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " center_2_act (Activation)      (None, 32, 32, 128)  0           ['center_2_bn[0][0]']            \n",
            "                                                                                                  \n",
            " g1_conv (Conv2D)               (None, 32, 32, 128)  16512       ['center_2_act[0][0]']           \n",
            "                                                                                                  \n",
            " g1_bn (BatchNormalization)     (None, 32, 32, 128)  512         ['g1_conv[0][0]']                \n",
            "                                                                                                  \n",
            " g1_act (Activation)            (None, 32, 32, 128)  0           ['g1_bn[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_9 (Conv2D)              (None, 32, 32, 128)  16512       ['g1_act[0][0]']                 \n",
            "                                                                                                  \n",
            " g_up_1 (Conv2DTranspose)       (None, 32, 32, 128)  147584      ['conv2d_9[0][0]']               \n",
            "                                                                                                  \n",
            " xl_1 (Conv2D)                  (None, 32, 32, 128)  32896       ['drop_conv4[0][0]']             \n",
            "                                                                                                  \n",
            " add_9 (Add)                    (None, 32, 32, 128)  0           ['g_up_1[0][0]',                 \n",
            "                                                                  'xl_1[0][0]']                   \n",
            "                                                                                                  \n",
            " activation_18 (Activation)     (None, 32, 32, 128)  0           ['add_9[0][0]']                  \n",
            "                                                                                                  \n",
            " drop_psi_1 (Dropout)           (None, 32, 32, 128)  0           ['activation_18[0][0]']          \n",
            "                                                                                                  \n",
            " psi_1 (Conv2D)                 (None, 32, 32, 1)    129         ['drop_psi_1[0][0]']             \n",
            "                                                                                                  \n",
            " activation_19 (Activation)     (None, 32, 32, 1)    0           ['psi_1[0][0]']                  \n",
            "                                                                                                  \n",
            " up_sampling2d_9 (UpSampling2D)  (None, 64, 64, 1)   0           ['activation_19[0][0]']          \n",
            "                                                                                                  \n",
            " psi_up_1 (Lambda)              (None, 64, 64, 64)   0           ['up_sampling2d_9[0][0]']        \n",
            "                                                                                                  \n",
            " q_attn_1 (Multiply)            (None, 64, 64, 64)   0           ['psi_up_1[0][0]',               \n",
            "                                                                  'drop_conv4[0][0]']             \n",
            "                                                                                                  \n",
            " q_attn_conv_1 (Conv2D)         (None, 64, 64, 64)   4160        ['q_attn_1[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_transpose_12 (Conv2DTra  (None, 64, 64, 32)  36896       ['center_2_act[0][0]']           \n",
            " nspose)                                                                                          \n",
            "                                                                                                  \n",
            " q_attn_bn_1 (BatchNormalizatio  (None, 64, 64, 64)  256         ['q_attn_conv_1[0][0]']          \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " up1 (Concatenate)              (None, 64, 64, 96)   0           ['conv2d_transpose_12[0][0]',    \n",
            "                                                                  'q_attn_bn_1[0][0]']            \n",
            "                                                                                                  \n",
            " g2_conv (Conv2D)               (None, 64, 64, 96)   9312        ['up1[0][0]']                    \n",
            "                                                                                                  \n",
            " g2_bn (BatchNormalization)     (None, 64, 64, 96)   384         ['g2_conv[0][0]']                \n",
            "                                                                                                  \n",
            " g2_act (Activation)            (None, 64, 64, 96)   0           ['g2_bn[0][0]']                  \n",
            "                                                                                                  \n",
            " g3_conv (Conv2D)               (None, 64, 64, 96)   9312        ['up1[0][0]']                    \n",
            "                                                                                                  \n",
            " conv2d_10 (Conv2D)             (None, 64, 64, 64)   6208        ['g2_act[0][0]']                 \n",
            "                                                                                                  \n",
            " g3_bn (BatchNormalization)     (None, 64, 64, 96)   384         ['g3_conv[0][0]']                \n",
            "                                                                                                  \n",
            " g_up_2 (Conv2DTranspose)       (None, 64, 64, 64)   36928       ['conv2d_10[0][0]']              \n",
            "                                                                                                  \n",
            " xl_2 (Conv2D)                  (None, 64, 64, 64)   16448       ['drop_conv3[0][0]']             \n",
            "                                                                                                  \n",
            " g3_act (Activation)            (None, 64, 64, 96)   0           ['g3_bn[0][0]']                  \n",
            "                                                                                                  \n",
            " add_10 (Add)                   (None, 64, 64, 64)   0           ['g_up_2[0][0]',                 \n",
            "                                                                  'xl_2[0][0]']                   \n",
            "                                                                                                  \n",
            " conv2d_11 (Conv2D)             (None, 64, 64, 32)   3104        ['g3_act[0][0]']                 \n",
            "                                                                                                  \n",
            " activation_20 (Activation)     (None, 64, 64, 64)   0           ['add_10[0][0]']                 \n",
            "                                                                                                  \n",
            " g_up_3 (Conv2DTranspose)       (None, 128, 128, 32  9248        ['conv2d_11[0][0]']              \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " xl_3 (Conv2D)                  (None, 128, 128, 32  4128        ['conv2_2_act[0][0]']            \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " drop_psi_2 (Dropout)           (None, 64, 64, 64)   0           ['activation_20[0][0]']          \n",
            "                                                                                                  \n",
            " add_11 (Add)                   (None, 128, 128, 32  0           ['g_up_3[0][0]',                 \n",
            "                                )                                 'xl_3[0][0]']                   \n",
            "                                                                                                  \n",
            " psi_2 (Conv2D)                 (None, 64, 64, 1)    65          ['drop_psi_2[0][0]']             \n",
            "                                                                                                  \n",
            " activation_22 (Activation)     (None, 128, 128, 32  0           ['add_11[0][0]']                 \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " activation_21 (Activation)     (None, 64, 64, 1)    0           ['psi_2[0][0]']                  \n",
            "                                                                                                  \n",
            " drop_psi_3 (Dropout)           (None, 128, 128, 32  0           ['activation_22[0][0]']          \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " up_sampling2d_10 (UpSampling2D  (None, 128, 128, 1)  0          ['activation_21[0][0]']          \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " psi_3 (Conv2D)                 (None, 128, 128, 1)  33          ['drop_psi_3[0][0]']             \n",
            "                                                                                                  \n",
            " psi_up_2 (Lambda)              (None, 128, 128, 64  0           ['up_sampling2d_10[0][0]']       \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " activation_23 (Activation)     (None, 128, 128, 1)  0           ['psi_3[0][0]']                  \n",
            "                                                                                                  \n",
            " q_attn_2 (Multiply)            (None, 128, 128, 64  0           ['psi_up_2[0][0]',               \n",
            "                                )                                 'drop_conv3[0][0]']             \n",
            "                                                                                                  \n",
            " up_sampling2d_11 (UpSampling2D  (None, 256, 256, 1)  0          ['activation_23[0][0]']          \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " q_attn_conv_2 (Conv2D)         (None, 128, 128, 64  4160        ['q_attn_2[0][0]']               \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " psi_up_3 (Lambda)              (None, 256, 256, 32  0           ['up_sampling2d_11[0][0]']       \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_transpose_13 (Conv2DTra  (None, 128, 128, 64  55360      ['up1[0][0]']                    \n",
            " nspose)                        )                                                                 \n",
            "                                                                                                  \n",
            " q_attn_bn_2 (BatchNormalizatio  (None, 128, 128, 64  256        ['q_attn_conv_2[0][0]']          \n",
            " n)                             )                                                                 \n",
            "                                                                                                  \n",
            " q_attn_3 (Multiply)            (None, 256, 256, 32  0           ['psi_up_3[0][0]',               \n",
            "                                )                                 'conv2_2_act[0][0]']            \n",
            "                                                                                                  \n",
            " up2 (Concatenate)              (None, 128, 128, 12  0           ['conv2d_transpose_13[0][0]',    \n",
            "                                8)                                'q_attn_bn_2[0][0]']            \n",
            "                                                                                                  \n",
            " q_attn_conv_3 (Conv2D)         (None, 256, 256, 32  1056        ['q_attn_3[0][0]']               \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_transpose_14 (Conv2DTra  (None, 256, 256, 32  36896      ['up2[0][0]']                    \n",
            " nspose)                        )                                                                 \n",
            "                                                                                                  \n",
            " q_attn_bn_3 (BatchNormalizatio  (None, 256, 256, 32  128        ['q_attn_conv_3[0][0]']          \n",
            " n)                             )                                                                 \n",
            "                                                                                                  \n",
            " up3 (Concatenate)              (None, 256, 256, 64  0           ['conv2d_transpose_14[0][0]',    \n",
            "                                )                                 'q_attn_bn_3[0][0]']            \n",
            "                                                                                                  \n",
            " conv2d_transpose_15 (Conv2DTra  (None, 512, 512, 32  18464      ['up3[0][0]']                    \n",
            " nspose)                        )                                                                 \n",
            "                                                                                                  \n",
            " up4 (Concatenate)              (None, 512, 512, 64  0           ['conv2d_transpose_15[0][0]',    \n",
            "                                )                                 'conv1_2_act[0][0]']            \n",
            "                                                                                                  \n",
            " final (Conv2D)                 (None, 512, 512, 1)  65          ['up4[0][0]']                    \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 848,740\n",
            "Trainable params: 846,500\n",
            "Non-trainable params: 2,240\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o3D8TbEV8wME"
      },
      "source": [
        "# Visualize Segmentations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bRodoNaK8w5S"
      },
      "source": [
        "def plot_image_with_overlay(image_slice: Slice, prediction):\n",
        "  image = image_slice.image\n",
        "  ground_truth = image_slice.ground_truth_mask\n",
        "\n",
        "  fig = plt.figure(figsize=(15, 15))\n",
        "  ax = fig.add_subplot(1, 5, 1)\n",
        "  ax.set_title('Original image')\n",
        "  ax.imshow(image, cmap='gray', interpolation=None)\n",
        "  ax = fig.add_subplot(1, 5, 2)\n",
        "  ax.set_title('Ground truth mask')\n",
        "  ax.imshow(ground_truth, cmap='gray', interpolation=None)\n",
        "  ax = fig.add_subplot(1, 5, 3)\n",
        "  ax.set_title('Image with ground truth mask')\n",
        "  ax.imshow(image, cmap='gray', interpolation=None)\n",
        "  ax.imshow(ground_truth, cmap='gray', alpha=0.5, interpolation=None)\n",
        "  ax = fig.add_subplot(1, 5, 4)\n",
        "  ax.set_title('Predicted mask')\n",
        "  ax.imshow(prediction, cmap='gray', interpolation=None)\n",
        "  ax = fig.add_subplot(1, 5, 5)\n",
        "  ax.set_title('Image with predicted mask')\n",
        "  ax.imshow(image, cmap='gray', interpolation=None)\n",
        "  ax.imshow(prediction, cmap='gray', alpha=0.5, interpolation=None)\n",
        "\n",
        "def plot_image_slice(image_slice: Slice, prediction):\n",
        "  plot_image_with_overlay(image_slice, prediction=prediction)\n",
        "\n",
        "def get_prediction(saved_model, image, expand_dims=False):\n",
        "  image = np.expand_dims(image, axis=0)\n",
        "  if expand_dims:\n",
        "    image = np.expand_dims(image, axis=3)\n",
        "  prediction = saved_model(image, training=False).numpy()\n",
        "  # prediction = (prediction > 0.5).astype(np.float32)\n",
        "  return np.squeeze(prediction)\n",
        "\n",
        "def eval_batch(saved_model, expand_dims, evaluation_image_paths, df, threshold):\n",
        "  for image_path in evaluation_image_paths:\n",
        "    print(image_path)\n",
        "    image_df = df.loc[df.image_path == image_path]\n",
        "    image_slice = load_single_example(image_path, image_df, gated_dir)\n",
        "    prediction = get_prediction(saved_model, image_slice.image, expand_dims)\n",
        "    if threshold:\n",
        "      prediction = (prediction > threshold).astype(np.float32)\n",
        "    print(f'prediction sum {np.sum(prediction)} and gt sum {np.sum(image_slice.ground_truth_mask)}')\n",
        "    plot_image_slice(image_slice, prediction)\n",
        "  \n",
        "eval_image_paths = sample_images(df, 'test', num_positives=40, num_negatives=15, shuffle=True)\n",
        "eval_batch(focal_attention_model,\n",
        "           True,\n",
        "           eval_image_paths,\n",
        "           df,\n",
        "           threshold=0.5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pP8ts_6noLRx"
      },
      "source": [
        "# Define data generator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2EcUhvjAoMiW"
      },
      "source": [
        "def normalize_image(image: np.ndarray):\n",
        "  \"\"\"Normalize pixels to the range [0, 1].\"\"\"\n",
        "  image_min = np.min(image)\n",
        "  image_range = np.max(image) - image_min\n",
        "  return ((image - image_min)/ image_range).astype(np.float32)\n",
        "  # return image / np.max(image)\n",
        "\n",
        "def create_mask(image: np.ndarray, lesions: List[Lesion]):\n",
        "  height, width = image.shape\n",
        "  if not lesions:\n",
        "    return np.zeros((height, width), dtype=np.float32)\n",
        "  all_bool_masks = []\n",
        "  for lesion in lesions:\n",
        "    lesion_points = [(p[1], p[0]) for p in lesion.points]\n",
        "    poly_path = Path(lesion_points)\n",
        "    x, y = np.mgrid[:height, :width]\n",
        "    coordinates = np.hstack((x.reshape(-1,1), y.reshape(-1,1)))\n",
        "    bool_mask = poly_path.contains_points(coordinates).reshape(height, width)\n",
        "    all_bool_masks.append(bool_mask)\n",
        "  out_mask = np.zeros((height, width))\n",
        "  for mask in all_bool_masks:\n",
        "    out_mask += mask\n",
        "  return out_mask.astype(np.float32)\n",
        "\n",
        "def load_single_example(image_path, image_df, gated_dir): \n",
        "  def get_dicom_attributes(dicom):\n",
        "    raw_image = image\n",
        "    pixel_spacing = None\n",
        "    slice_thickness = None\n",
        "    rescale_intercept = None\n",
        "    rescale_slope = None\n",
        "    try:\n",
        "      rescale_slope = float(dicom.get('RescaleSlope'))\n",
        "      rescale_intercept = float(dicom.get('RescaleIntercept'))\n",
        "      slice_thickness = float(dicom.get('SliceThickness'))\n",
        "      pixel_spacing = dicom.get('PixelSpacing')\n",
        "      pixel_spacing = [(float(ps[0]), float(ps[1])) for ps in pixel_spacing]\n",
        "    except:\n",
        "      logging.error(f'Image {image_path} is missing dicom attribute(s).')\n",
        "    return DicomAttributes(\n",
        "        pixel_spacing = pixel_spacing,\n",
        "        rescale_intercept = rescale_intercept,\n",
        "        rescale_slope = rescale_slope,\n",
        "        slice_thickness = slice_thickness,\n",
        "    )\n",
        "\n",
        "  assert image_df.image_path.nunique() == 1\n",
        "  full_image_path = os.path.join(gated_dir, image_path[1:])\n",
        "  dicom = pydicom.dcmread(full_image_path)\n",
        "  image = dicom.pixel_array\n",
        "  raw_image = image\n",
        "  image = normalize_image(image)\n",
        "  dicom_attributes = get_dicom_attributes(dicom)\n",
        "  lesions = []\n",
        "  for _, lesion_row in image_df.iterrows():\n",
        "    if isinstance(lesion_row.lesion_points, float):\n",
        "      # No lesions for this image\n",
        "      continue\n",
        "    lesions.append(Lesion(\n",
        "        artery=lesion_row.artery,\n",
        "        points = lesion_row.lesion_points))\n",
        "  mask = create_mask(image, lesions)\n",
        "  assert image_df.patient_id.nunique() == 1\n",
        "  assert image_df.patient_split.nunique() == 1, f'Patient {image_df.iloc[0].patient_id} in {image_df.patient_split.unique()}'\n",
        "  assert image_df.has_calcification.nunique() == 1\n",
        "  \n",
        "  if np.isnan(image_df.iloc[0].image_agatston):\n",
        "    ground_truth_agatston = None\n",
        "  else:\n",
        "    ground_truth_agatston = image_df.iloc[0].image_agatston\n",
        "  return Slice(\n",
        "      patient_id = image_df.iloc[0].patient_id,\n",
        "      image_path = image_path,\n",
        "      patient_split = image_df.iloc[0].patient_split,\n",
        "      has_calcification = image_df.iloc[0].has_calcification,\n",
        "      lesions = lesions,\n",
        "      image = image,\n",
        "      ground_truth_mask = mask,\n",
        "      dicom_attributes = dicom_attributes,\n",
        "      raw_image = raw_image, # TODO: delete\n",
        "      ground_truth_agatston = ground_truth_agatston\n",
        "  )\n",
        "\n",
        "def load_example(image_path, df, gated_dir):\n",
        "  image_df = df.loc[df.image_path == image_path]\n",
        "  example = load_single_example(image_path, image_df, gated_dir)\n",
        "  return example\n",
        "\n",
        "class DataGenerator(tf.keras.utils.Sequence):\n",
        "  def __init__(self,\n",
        "               df: pd.DataFrame,\n",
        "               name: Text,\n",
        "               image_paths: List[Text],\n",
        "               batch_size: int,\n",
        "               gated_dir: Text,\n",
        "               positive_upsample_factor,\n",
        "               add_dim: bool = False):\n",
        "    self.df = df\n",
        "    self.name = name\n",
        "    self.batch_size = batch_size\n",
        "    self.gated_dir = gated_dir\n",
        "    self.add_dim = add_dim\n",
        "    if positive_upsample_factor:\n",
        "      original_length = len(image_paths)\n",
        "      positive_image_paths = set(df.loc[(df.image_path.isin(image_paths)) & (df.has_calcification == True)].image_path)\n",
        "      upsampled_positive_image_paths = list(positive_image_paths) * positive_upsample_factor\n",
        "      image_paths = image_paths + upsampled_positive_image_paths\n",
        "      additional_images = len(image_paths)-original_length\n",
        "      print(f'Added {additional_images} images from {len(positive_image_paths)} original positives')\n",
        "    else:\n",
        "      print(f'No upsampling for {name}')\n",
        "    np.random.shuffle(image_paths)\n",
        "    self.image_paths = image_paths\n",
        "    \n",
        "  def __len__(self):\n",
        "    length = math.ceil(len(self.image_paths) / self.batch_size)\n",
        "    print(f'For {self.name} datagen length is {length}')\n",
        "    return length\n",
        "\n",
        "  def _prepare_batch(self, df, gated_dir): # TODO: rename to batch_df\n",
        "    X_list = []\n",
        "    Y_list = []\n",
        "    image_slices = []\n",
        "    grouped_df = df.groupby('image_path')\n",
        "    for i, (image_path, image_df) in enumerate(grouped_df):\n",
        "      image_slice = load_single_example(image_path, image_df, gated_dir) \n",
        "      image_slices.append(image_slice)\n",
        "      if self.add_dim:\n",
        "        X_list.append(np.expand_dims(image_slice.image, axis=2))\n",
        "      else:\n",
        "        X_list.append(image_slice.image)\n",
        "      Y_list.append(image_slice.ground_truth_mask)\n",
        "    X = np.array(X_list)\n",
        "    Y = np.array(Y_list)\n",
        "    return X, Y, image_slices\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    batch_image_paths = self.image_paths[idx * self.batch_size: (idx+1) * self.batch_size]\n",
        "    batch_metadata_df = self.df[self.df.image_path.isin(batch_image_paths)]\n",
        "    X, Y, image_slices = self._prepare_batch(batch_metadata_df, self.gated_dir)\n",
        "    return X, Y, image_slices\n",
        "\n",
        "  def on_epoch_end(self):\n",
        "    np.random.shuffle(self.image_paths)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8BzeOT3jnkSa"
      },
      "source": [
        "# Agatston with data generator"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BSVTzlJak0wA"
      },
      "source": [
        "## Compute"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "57eoFRgUnNdr"
      },
      "source": [
        "def compute_agatston_with_data_gen(\n",
        "    model,\n",
        "    data_generator: tf.keras.utils.Sequence,\n",
        "    threshold,\n",
        "    write_frequency_batches,\n",
        "    write_dir,\n",
        "    num_batches=None):\n",
        "  \"\"\"\n",
        "    Args:\n",
        "      num_batches: number of batches to process. \n",
        "  \"\"\"\n",
        "  record_columns = ['patient_id', 'image_path', 'image_predicted_agatston',\n",
        "                    'image_gt_agatston']\n",
        "  if num_batches:\n",
        "    assert num_batches <= data_generator.__len__(), 'Requesting too many batches'\n",
        "  else:\n",
        "    num_batches = data_generator.__len__()\n",
        "  agatston_records = []\n",
        "  for batch_num in range(num_batches):\n",
        "    print(f'Batch {batch_num}')\n",
        "    batch_X, batch_Y, image_slices = data_generator.__getitem__(batch_num)\n",
        "    batch_predictions = model.predict_on_batch(batch_X)\n",
        "    batch_predictions = np.squeeze(batch_predictions)\n",
        "    if len(batch_predictions.shape) == 2:\n",
        "      batch_predictions = np.expand_dims(batch_predictions, axis=0)\n",
        "    assert len(batch_predictions.shape) == 3, 'Expected [batch_size, 512, 512] predictions'\n",
        "    for i in range(batch_predictions.shape[0]):\n",
        "      image_slice = image_slices[i]\n",
        "      prediction = batch_predictions[i, :, :]\n",
        "      image_slices[i].predicted_mask = prediction\n",
        "      prediction = (prediction > threshold).astype(np.float32)\n",
        "      predicted_agatston = compute_agatston_for_slice(image_slices[i],\n",
        "                                            predicted_mask=prediction)\n",
        "      image_slices[i].predicted_agatston = predicted_agatston\n",
        "      ground_truth_agatston = compute_agatston_for_slice(image_slices[i],\n",
        "                                                         predicted_mask=None)\n",
        "      image_slices[i].ground_truth_agatston = ground_truth_agatston\n",
        "      agatston_record = (image_slices[i].patient_id,\n",
        "                         image_slices[i].image_path,\n",
        "                         predicted_agatston,\n",
        "                         image_slices[i].ground_truth_agatston)\n",
        "      agatston_records.append(agatston_record)\n",
        "    if batch_num % write_frequency_batches == 0:\n",
        "      fname = os.path.join(write_dir, f'agatston_{batch_num}.csv')\n",
        "      write_df(fname, pd.DataFrame.from_records(agatston_records,\n",
        "                            columns=record_columns))\n",
        "  agatston_df = pd.DataFrame.from_records(agatston_records,\n",
        "                            columns=record_columns)\n",
        "  return agatston_df=\n",
        "\n",
        "def run_agatston(model,\n",
        "                 df,\n",
        "                 image_paths,\n",
        "                 batch_size,\n",
        "                 num_images,\n",
        "                 threshold,\n",
        "                 write_frequency_batches: int,\n",
        "                 write_dir: Text,\n",
        "                 name: Text = ''):\n",
        "  if not os.path.exists(write_dir):\n",
        "    os.makedirs(write_dir)\n",
        "  data_gen = DataGenerator(\n",
        "    df,\n",
        "    name=name,\n",
        "    image_paths=image_paths,\n",
        "    batch_size=batch_size,\n",
        "    gated_dir=gated_dir,\n",
        "    positive_upsample_factor=0)\n",
        "  if num_images:\n",
        "    num_batches = math.ceil(num_images / batch_size)\n",
        "  else:\n",
        "    num_batches = None\n",
        "  out = compute_agatston_with_data_gen(\n",
        "    model=model,\n",
        "    data_generator=data_gen,\n",
        "    threshold=threshold,\n",
        "    num_batches=num_batches,\n",
        "    write_frequency_batches=write_frequency_batches,\n",
        "    write_dir=write_dir,\n",
        "    )\n",
        "  return out\n",
        "\n",
        "write_dir = os.path.join(project_base_dir, 'agatston', 'focal_model')\n",
        "\n",
        "out = run_agatston(\n",
        "    model=focal_model,\n",
        "    df=df,\n",
        "    image_paths=test_image_paths,\n",
        "    batch_size=32,\n",
        "    num_images = None,\n",
        "    threshold=0.76,\n",
        "    write_frequency_batches=20,\n",
        "    write_dir = write_dir,\n",
        ")\n",
        "\n",
        "  \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t8GnK5yTA_xh"
      },
      "source": [
        "## Get volume-level score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IxBZrDNPlDgY"
      },
      "source": [
        "volume_gt = fixed_ag.groupby('patient_id').agg(lambda x: x.image_gt_agatston.sum()).image_gt_agatston"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pxYQNuF9exj4"
      },
      "source": [
        "# Find best threshold"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yLTiDq9zxg2j"
      },
      "source": [
        "positive_tune_image_paths = list(df.loc[(df.patient_split == 'tune') & (df.has_calcification == True)].image_path.unique())\n",
        "positive_test_image_paths = list(df.loc[(df.patient_split == 'test') & (df.has_calcification == True)].image_path.unique())\n",
        "\n",
        "def verify_df(df, positive_image_paths):\n",
        "  a = df.loc[df.image_path.isin(positive_image_paths)]\n",
        "  assert len(a.loc[pd.isnull(a.image_agatston)]) == 0\n",
        "\n",
        "verify_df(df, positive_tune_image_paths)\n",
        "verify_df(df, positive_test_image_paths)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hzJoAj7pP8_6",
        "outputId": "74deed73-723d-448c-90d0-19d8ea83906c"
      },
      "source": [
        "example = load_example(positive_tune_image_paths[5], df, gated_dir)\n",
        "input = np.expand_dims(example.image, axis=0)\n",
        "example_prediction = upsample_dice_model.predict(input)\n",
        "example_prediction = np.squeeze(example_prediction)\n",
        "binarized_prediction = (example_prediction > 0.5).astype(np.float32)\n",
        "compute_agatston_for_slice(example, predicted_mask = binarized_prediction)\n",
        "                                              # predicted_mask=binarized_prediction)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VAF3Mq74flkZ"
      },
      "source": [
        "def select_threshold_with_data_gen(\n",
        "    model,\n",
        "    df,\n",
        "    positives_data_generator: tf.keras.utils.Sequence,\n",
        "    num_batches,\n",
        "    thresholds):\n",
        "  \"\"\"\n",
        "    Args:\n",
        "      df: parsed_lesions_with_gt_ag\n",
        "      positives_data_generator: Produces positive examples only.\n",
        "      num_batches: number of batches to process. \n",
        "  \"\"\"\n",
        "  assert num_batches <= positives_data_generator.__len__(), 'Requesting too many batches'\n",
        "  agatston_records = []\n",
        "  # Maps from each threshold to a list of MSEs encountered for it\n",
        "  threshold_to_errors = collections.defaultdict(list)\n",
        "  ag_history = collections.defaultdict(dict)\n",
        "  for batch_num in range(num_batches):\n",
        "    print(f'Processing batch {batch_num}')\n",
        "    batch_X, batch_Y, image_slices = positives_data_generator.__getitem__(batch_num)\n",
        "    batch_predictions = model.predict_on_batch(batch_X)\n",
        "    batch_predictions = np.squeeze(batch_predictions)\n",
        "    if len(batch_predictions.shape) != 3:\n",
        "      # assert len(batch_predictions.shape) == 3, 'Expected [batch_size, 512, 512] predictions'\n",
        "      print(f'Unexpected shape of {batch_predictions.shape}')\n",
        "      continue\n",
        "    for threshold in thresholds:\n",
        "      for i in range(batch_predictions.shape[0]):\n",
        "        prediction = batch_predictions[i, :, :]\n",
        "        binarized_prediction = (prediction > threshold).astype(np.float32)\n",
        "        predicted_agatston = compute_agatston_for_slice(image_slices[i], predicted_mask=binarized_prediction)\n",
        "        image_slices[i].predicted_agatston = predicted_agatston\n",
        "        ag_history[image_slices[i].image_path][threshold] = predicted_agatston\n",
        "        # try:\n",
        "        gt_agatston = image_slices[i].ground_truth_agatston\n",
        "        assert type(predicted_agatston) == int , f'Type is {type(predicted_agatston)}'\n",
        "        diff = abs(predicted_agatston - gt_agatston)\n",
        "        threshold_to_errors[str(threshold)].append(diff)  \n",
        "  # agatston_df = pd.DataFrame.from_records(agatston_records,\n",
        "                            # columns=['image_path', 'predicted_image_agatston', 'image_calc_pixel_count'])\n",
        "  threshold_errors_df = pd.DataFrame(threshold_to_errors)\n",
        "  return threshold_errors_df, ag_history\n",
        "\n",
        "\n",
        "def select_threshold(model,\n",
        "                     image_paths,\n",
        "                     df,\n",
        "                     num_images,\n",
        "                     thresholds,\n",
        "                     batch_size=32,\n",
        "                     shuffle=True):\n",
        "  if shuffle:\n",
        "    np.random.shuffle(image_paths)\n",
        "  num_batches = math.ceil(num_images / batch_size)\n",
        "  data_gen = DataGenerator(\n",
        "      df,\n",
        "      name='',\n",
        "      image_paths=image_paths,\n",
        "      batch_size=batch_size,\n",
        "      gated_dir=gated_dir,\n",
        "      positive_upsample_factor=0,\n",
        "  )\n",
        "  thresholds_out = select_threshold_with_data_gen(\n",
        "                    model,\n",
        "                    df,\n",
        "                    data_gen,\n",
        "                    num_batches=num_batches,\n",
        "                    thresholds=thresholds )\n",
        "  return thresholds_out\n",
        "\n",
        "ORIG_THRESHOLDS = [0.1, 0.2, 0.3, 0.4, 0.45, 0.5, 0.55, 0.6, 0.65, 0.7, 0.75, 0.8, 0.85, 0.9]\n",
        "FOCUSED_THRESHOLDS = [0.66, 0.67, 0.68, 0.69, 0.7, 0.71, 0.72, 0.73, 0.74, 0.75, 0.76, 0.77, 0.78]\n",
        "thresholds_out = select_threshold(\n",
        "    model=focal_attention_model,\n",
        "    image_paths=tune_image_paths,\n",
        "    df=df,\n",
        "    num_images=3902,\n",
        "    thresholds=ORIG_THRESHOLDS,\n",
        ")\n",
        "\n",
        "threshold_history_fname = os.path.join(project_base_dir, 'agatston', 'focal_attention_threshold_errors.csv')\n",
        "write_df(threshold_history_fname, thresholds_out[0])\n",
        "ag_history_file = os.path.join(project_base_dir, 'agatston', 'focal_attention_ag_history.csv')\n",
        "with open(ag_history_file, 'wb') as f:\n",
        "  pickle.dump(thresholds_out[1], f)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ymYLJyiBMHf"
      },
      "source": [
        "error_dict = collections.defaultdict(list) # Map from threshold to list of absolute error\n",
        "gt_scores = gt_scores.set_index('image_path')\n",
        "missing_count = 0\n",
        "for image_path, thresholds_dict in ag_history.items():\n",
        "  for threshold, predicted_score in thresholds_dict.items():\n",
        "    if image_path not in gt_scores.index:\n",
        "      missing_count += 1\n",
        "      continue\n",
        "    gt_score = gt_scores.loc[image_path].image_gt_agatston\n",
        "    error_dict[str(threshold)].append(abs(gt_score - predicted_score))\n",
        "errors_df = pd.DataFrame(error_dict)    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QMac97HdsXI9"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        },
        "id": "pbhnFpYVsBQc",
        "outputId": "bf48e509-4f56-48e1-887a-44dfef12d2ea"
      },
      "source": [
        "get_threshold(errors_df)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.1     3.211002\n",
            "0.2     2.103306\n",
            "0.3     1.658058\n",
            "0.4     1.423554\n",
            "0.45    1.351240\n",
            "0.5     1.330837\n",
            "0.55    1.346591\n",
            "0.6     1.385847\n",
            "0.65    1.461519\n",
            "0.7     1.551911\n",
            "0.75    1.676136\n",
            "0.8     1.816632\n",
            "0.85    1.985537\n",
            "0.9     2.220558\n",
            "dtype: float64\n",
            "Best threshold: 0.5 and MSE: 1.3308367768595042\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8c64ygyri75Y"
      },
      "source": [
        "def get_threshold(threshold_errors_df):\n",
        "  mses = np.mean(threshold_errors_df)\n",
        "  min_idx = mses.argmin()\n",
        "  best_threshold = mses.index[min_idx]\n",
        "  best_threshold_mse = mses.iloc[min_idx]\n",
        "  plt.plot(list(mses.index), list(mses))\n",
        "  plt.title('Image-level Agatston Error')\n",
        "  plt.xlabel('Threshold')\n",
        "  plt.ylabel('Absolute Error')\n",
        "  plt.show()\n",
        "  print(mses)\n",
        "  print(f'Best threshold: {best_threshold} and MSE: {best_threshold_mse}')\n",
        "\n",
        "# get_threshold(thresholds_out[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-wjU_26_zhEM"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kXfgXX0iUFQW"
      },
      "source": [
        "df.sort_values(by='image_agatston', ascending=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 352
        },
        "id": "Nt56VVrjULwl",
        "outputId": "89852bc8-bf1f-40d8-eb0b-abbc7b50d9b4"
      },
      "source": [
        "plt.hist(list(df.image_agatston))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([7.891e+03, 1.760e+02, 9.500e+01, 4.700e+01, 2.100e+01, 3.000e+00,\n",
              "        5.000e+00, 4.000e+00, 2.000e+00, 1.000e+00]),\n",
              " array([   0. ,  176.2,  352.4,  528.6,  704.8,  881. , 1057.2, 1233.4,\n",
              "        1409.6, 1585.8, 1762. ]),\n",
              " <a list of 10 Patch objects>)"
            ]
          },
          "metadata": {},
          "execution_count": 79
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}